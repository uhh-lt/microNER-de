{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import fastText\n",
    "import math\n",
    "import linecache\n",
    "import numpy as np \n",
    "from numpy import random\n",
    "from random import sample\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform\n",
    "import re\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "# from attention_utils import get_activations, get_data_recurrent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ft = fastText.load_model(\"/home/jindal/notebooks/fastText/wiki.de.bin\")\n",
    "\n",
    "nb_embedding_dims = ft.get_dimension()\n",
    "nb_sequence_length = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def twitter_tokenizer(textline):\n",
    "    textLine = re.sub(r'http\\S+', 'URL', textline)\n",
    "    textline = re.sub('@[\\w_]+', 'USER_MENTION', textline)\n",
    "    textline = re.sub('\\|LBR\\|', '', textline)\n",
    "    textline = re.sub('\\.\\.\\.+', '...', textline)\n",
    "    textline = re.sub('!!+', '!!', textline)\n",
    "    textline = re.sub('\\?\\?+', '??', textline)\n",
    "    words = re.compile('[\\U00010000-\\U0010ffff]|[\\w-]+|[^ \\w\\U00010000-\\U0010ffff]+', re.UNICODE).findall(textline.strip())\n",
    "    words = [w.strip() for w in words if w.strip() != '']\n",
    "    # print(words)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_ft = {}\n",
    "def process_features(textline, nb_sequence_length, nb_embedding_dims, tokenize=True):\n",
    "    if not tokenize:\n",
    "        words = textline.split()\n",
    "    else:\n",
    "        words = twitter_tokenizer(textline)\n",
    "    features_ft = np.zeros((nb_sequence_length, nb_embedding_dims))\n",
    "    features_idx = np.zeros(nb_sequence_length)\n",
    "    max_words = min(len(words), nb_sequence_length)\n",
    "    idx = nb_sequence_length - len(words[:max_words])\n",
    "    for w in words[:max_words]:\n",
    "        if w in word_vectors_ft:\n",
    "            wv = word_vectors_ft[w]\n",
    "        else:\n",
    "            wv = ft.get_word_vector(w.lower())\n",
    "            word_vectors_ft[w] = wv\n",
    "        features_ft[idx] = wv\n",
    "        \n",
    "        idx = idx + 1\n",
    "    return features_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sequential_generator(filename, \n",
    "                         batch_size, \n",
    "                         labels2Idx:'dict to make output labels',\n",
    "                         check:'to check if all lines in file are of same length.To check enter the len of line after splitting it by tabs' = None,\n",
    "                         tokenize:'specify if using twitter tokenzor to preprocess lines'=False, \n",
    "                        ):    \n",
    "    \n",
    "    f = open(filename)\n",
    "    n_labels = len(labels2Idx)\n",
    "    while True:\n",
    "        batch_features_ft = np.zeros((batch_size, nb_sequence_length, nb_embedding_dims))\n",
    "        batch_labels = np.zeros((batch_size, len(labels2Idx)))\n",
    "        for i in range(batch_size):\n",
    "            line = f.readline()\n",
    "            if (\"\" == line):\n",
    "                f.seek(0)\n",
    "                line = f.readline()\n",
    "            data = line.strip().split('\\t')\n",
    "            if check:\n",
    "                if len(data)!=check:\n",
    "                    i-=1\n",
    "                    continue\n",
    "            batch_features_ft[i] = process_features(data[0], nb_sequence_length, nb_embedding_dims, tokenize= tokenize)\n",
    "            if len(labels2Idx)==2:\n",
    "                batch_labels[i] = to_categorical(0 if data[2] == 'OTHER' else 1, n_labels)\n",
    "            else:\n",
    "                batch_labels[i] = to_categorical(labels2Idx[data[2]], n_labels)\n",
    "        yield ([batch_features_ft], batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_sentences(filetrain,filedev, check:'to check if lines of file are all same lenght after separating by tab'):\n",
    "    labels2Idx = {}\n",
    "    train_lines = [line.strip().split(\"\\t\") for line in open(filetrain) if len(line.strip().split('\\t'))==check]\n",
    "    dev_lines = [line.strip().split(\"\\t\") for line in open(filedev) if len(line.strip().split('\\t'))==check]\n",
    "\n",
    "    train_sentences = [x[0] for x in train_lines]\n",
    "    for dataset in [train_lines, dev_lines]:\n",
    "        for line in dataset:\n",
    "            label = line[2]\n",
    "            if label not in labels2Idx.keys():\n",
    "                labels2Idx[label]= len(labels2Idx)\n",
    "                \n",
    "#     train_labels = [0 if x[1] == \"OTHER\" else 1 for x in train_lines]\n",
    "    train_labels = [labels2Idx[x[2]] for x in train_lines]\n",
    "    dev_sentences = [x[0] for x in dev_lines]\n",
    "#     dev_labels = [0 if x[1] == \"OTHER\" else 1 for x in dev_lines]\n",
    "    dev_labels = [labels2Idx[x[2]] for x in dev_lines]\n",
    "    return (train_sentences, train_labels, dev_sentences, dev_labels, labels2Idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-a56c66fdbd93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_train.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_dev.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels2Id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dev_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiletrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiledev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-7327903c63a8>\u001b[0m in \u001b[0;36mtrain_dev_sentences\u001b[0;34m(filetrain, filedev, check)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_lines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels2Idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mlabels2Idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels2Idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "file_train = '/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_train.csv'\n",
    "file_dev = '/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_dev.csv'\n",
    "train_sentences, train_labels, dev_sentences, dev_labels, labels2Id = train_dev_sentences(filetrain=file_train,filedev=file_dev, check=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dann diskutiere es doch mit dir selbst.'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels =len(labels2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(no_labels:'total labels for classification'):\n",
    "    model_input_embedding = Input(shape = (nb_sequence_length, nb_embedding_dims))\n",
    "    lstm_block = Bidirectional(LSTM(100, dropout = 0.5, return_sequences=True))(model_input_embedding)\n",
    "    lstm_block = LeakyReLU()(lstm_block)\n",
    "\n",
    "    filter_sizes = (3, 4, 5)\n",
    "    conv_blocks = []\n",
    "    for sz in filter_sizes:\n",
    "        conv = Conv1D(\n",
    "            filters = 200,\n",
    "            kernel_size = sz,\n",
    "            padding = 'valid',\n",
    "            strides = 1\n",
    "        )(lstm_block)\n",
    "        conv = LeakyReLU()(conv)\n",
    "        conv = GlobalMaxPooling1D()(conv)\n",
    "        conv = Dropout(0.5)(conv)\n",
    "        conv_blocks.append(conv)\n",
    "    model_concatenated = concatenate([conv_blocks[0], conv_blocks[1], conv_blocks[2]])\n",
    "    # model_concatenated = Dropout(0.8)(model_concatenated)\n",
    "    model_concatenated = Dense(100)(model_concatenated)\n",
    "    model_concatenated = LeakyReLU()(model_concatenated)\n",
    "    model_output = Dense(no_labels, activation = \"softmax\")(model_concatenated)\n",
    "    new_model = Model(model_input_embedding, model_output)\n",
    "    new_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics = ['accuracy'])\n",
    "#     new_model.summary()\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(generator, \n",
    "               train_sentences, \n",
    "               devLabels, \n",
    "               number_of_tests,\n",
    "               number_of_epochs,\n",
    "               filename_to_log, \n",
    "               labels_earlier:'number of original labels if loading a pretrained model',\n",
    "               filename_to_save_weigths,\n",
    "               batch_size, \n",
    "               train_file:'filepath for traininig',\n",
    "               f1_measure:'binary/macro etc', \n",
    "               pos_label:'only if binary f1',\n",
    "               labels2Idx,\n",
    "               load_model_weights=False,\n",
    "               model_weights_file:'give filepath as str'=None, \n",
    "               tokenize=True,\n",
    "               nb_sequence_length = nb_sequence_length,\n",
    "               nb_embedding_dims= nb_embedding_dims, \n",
    "               check_for_generator=None,\n",
    "                ):\n",
    "    \n",
    "#     f = open(filename_to_log,\"w\")\n",
    "    \n",
    "    max_f1=0\n",
    "    max_p=0\n",
    "    max_r=0\n",
    "    max_a=0\n",
    "    total_f1=0\n",
    "    total_prec=0\n",
    "    total_acc=0\n",
    "    total_recall=0\n",
    "    \n",
    "    for test_number in range(number_of_tests):\n",
    "        print(\"Test %d/%d\" %(test_number+1, number_of_tests))\n",
    "        model = compile_model(labels_earlier)\n",
    "\n",
    "        # transfer learning\n",
    "        if load_model_weights and model_weights_file:\n",
    "                model.load_weights(model_weights_file)\n",
    "\n",
    "        samples_per_epoch = len(train_sentences)\n",
    "        epochs = number_of_epochs\n",
    "        batch_size = batch_size\n",
    "        steps_per_epoch = math.ceil(samples_per_epoch / batch_size)\n",
    "        checkpoint = ModelCheckpoint(filename_to_save_weigths, monitor='val_acc',save_best_only = True, \n",
    "                                     save_weights_only = True)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch: %d\" %(epoch+1))\n",
    "            model.fit_generator(\n",
    "                generator(filename = train_file, batch_size = batch_size, check = check_for_generator, \n",
    "                          labels2Idx= labels2Idx,tokenize= tokenize), \n",
    "                steps_per_epoch= steps_per_epoch, epochs=1,\n",
    "                validation_data = generator(filename ='/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_dev.csv', \n",
    "                                            batch_size = batch_size, check = check_for_generator, \n",
    "                                           labels2Idx = labels2Idx, tokenize = tokenize),\n",
    "                validation_steps = math.ceil(len(dev_labels) / batch_size),\n",
    "                callbacks = [checkpoint]\n",
    "            )\n",
    "\n",
    "#             testset_features = np.zeros((len(dev_sentences), nb_sequence_length, nb_embedding_dims))\n",
    "#             for i in range(len(dev_sentences)):\n",
    "#                 testset_features[i] = process_features(dev_sentences[i], nb_sequence_length, nb_embedding_dims)\n",
    "#             results = model.predict(testset_features)\n",
    "\n",
    "\n",
    "# #             idx2Label = {0 : \"OTHER\", 1 : \"OFFENSIVE\"}\n",
    "#             predLabels = results.argmax(axis=-1)\n",
    "#             devLabels = devLabels\n",
    "#             f1 = f1_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label) # offensive is the major class. So other is minor\n",
    "#             r = recall_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label)\n",
    "#             p = precision_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label)\n",
    "#             a = accuracy_score(devLabels, predLabels)\n",
    "#             if max_f1 < f1:\n",
    "#                 print(\"model saved. F1 is %f\" %(f1))\n",
    "#                 model.save(filename_to_save_weigths)\n",
    "#                 max_f1 = f1\n",
    "#                 max_p = p\n",
    "#                 max_r = r\n",
    "#                 max_a = a\n",
    "#             text = \"prec: \"+ str(p)+\" rec: \"+str(r) +\" f1: \"+str(f1) +\" acc: \"+str(a)+\" \\n\"\n",
    "#             print(\"Test-Data: Prec: %.3f, Rec: %.3f, F1: %.3f, Acc: %.3f\" % (p, r, f1, a))\n",
    "#         to_write= \"prec: \"+ str(max_p)+\" rec: \"+str(max_r) +\" f1: \"+str(max_f1) +\" acc: \"+str(max_a)+\" \\n\"\n",
    "#         print(to_write)\n",
    "#         f.write(to_write)\n",
    "#         total_f1+=max_f1\n",
    "#         total_prec+=max_p\n",
    "#         total_acc+=max_a\n",
    "#         total_recall+=max_r    \n",
    "#         print(\"*****************************************************************************\")\n",
    "#     final_text = \"avg_prec: \" +str(total_prec/number_of_tests)+\" total_rec: \"+str(total_recall/number_of_tests) +\" total_f1: \"+str(total_f1/number_of_tests) +\" total_acc: \"+str(total_acc/number_of_tests)+\" \\n\"\n",
    "#     print(final_text)\n",
    "#     f.write(final_text)\n",
    "#     f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nationalistisches Geseiere.\n"
     ]
    }
   ],
   "source": [
    "print(dev_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = sequential_generator\n",
    "train_sentences = train_sentences\n",
    "devLabels = dev_labels\n",
    "number_of_tests = 1\n",
    "number_of_epochs = 10\n",
    "millionpostcorpus_pretraining_log = '/home/jindal/notebooks/jindal/NER/language_model/results_pretraining_millionpostcorpus.txt' \n",
    "millionpostcorpus_pretraining_save_weigths='/home/jindal/notebooks/jindal/NER/language_model/model_pretrained_millionpostcorpus.h5'\n",
    "batch_size=32\n",
    "millionpostcorpus_train_file='/home/jindal/notebooks/jindal/NER/language_model/million_post_corpus_train.csv'\n",
    "tokenize = True\n",
    "labels2Idx = labels2Id\n",
    "f1_measure='binary'\n",
    "pos_label=1\n",
    "load_model_weights=False\n",
    "# model_weights_file:'give filepath as str'=None, \n",
    "nb_sequence_length = nb_sequence_length\n",
    "nb_embedding_dims= nb_embedding_dims\n",
    "check_for_generator=2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1/3\n",
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 34s 261ms/step - loss: 0.4134 - acc: 0.8653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.831\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.3877 - acc: 0.8670\n",
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.829\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 216ms/step - loss: 0.3771 - acc: 0.8646\n",
      "model saved. F1 is 0.019802\n",
      "Test-Data: Prec: 0.333, Rec: 0.010, F1: 0.020, Acc: 0.829\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 214ms/step - loss: 0.3607 - acc: 0.8662\n",
      "Test-Data: Prec: 0.100, Rec: 0.010, F1: 0.019, Acc: 0.817\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.3435 - acc: 0.8679\n",
      "model saved. F1 is 0.117647\n",
      "Test-Data: Prec: 0.333, Rec: 0.071, F1: 0.118, Acc: 0.819\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.3186 - acc: 0.8757\n",
      "Test-Data: Prec: 0.174, Rec: 0.082, F1: 0.111, Acc: 0.779\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.2858 - acc: 0.8899\n",
      "model saved. F1 is 0.317073\n",
      "Test-Data: Prec: 0.264, Rec: 0.398, F1: 0.317, Acc: 0.710\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.2618 - acc: 0.8970\n",
      "Test-Data: Prec: 0.281, Rec: 0.276, F1: 0.278, Acc: 0.758\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.2274 - acc: 0.9060\n",
      "Test-Data: Prec: 0.292, Rec: 0.214, F1: 0.247, Acc: 0.779\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.2006 - acc: 0.9231\n",
      "Test-Data: Prec: 0.258, Rec: 0.235, F1: 0.246, Acc: 0.756\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.1776 - acc: 0.9278\n",
      "Test-Data: Prec: 0.290, Rec: 0.276, F1: 0.283, Acc: 0.763\n",
      "Epoch: 12\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.1532 - acc: 0.9384\n",
      "Test-Data: Prec: 0.280, Rec: 0.235, F1: 0.256, Acc: 0.769\n",
      "Epoch: 13\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.1402 - acc: 0.9472\n",
      "Test-Data: Prec: 0.276, Rec: 0.163, F1: 0.205, Acc: 0.786\n",
      "Epoch: 14\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.1243 - acc: 0.9543\n",
      "Test-Data: Prec: 0.268, Rec: 0.194, F1: 0.225, Acc: 0.774\n",
      "Epoch: 15\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.1022 - acc: 0.9628\n",
      "Test-Data: Prec: 0.208, Rec: 0.102, F1: 0.137, Acc: 0.782\n",
      "Epoch: 16\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0974 - acc: 0.9602\n",
      "Test-Data: Prec: 0.322, Rec: 0.286, F1: 0.303, Acc: 0.777\n",
      "Epoch: 17\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0844 - acc: 0.9680\n",
      "Test-Data: Prec: 0.271, Rec: 0.163, F1: 0.204, Acc: 0.784\n",
      "Epoch: 18\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.0699 - acc: 0.9718\n",
      "Test-Data: Prec: 0.318, Rec: 0.286, F1: 0.301, Acc: 0.775\n",
      "Epoch: 19\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0668 - acc: 0.9725\n",
      "Test-Data: Prec: 0.276, Rec: 0.163, F1: 0.205, Acc: 0.786\n",
      "Epoch: 20\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0592 - acc: 0.9770\n",
      "Test-Data: Prec: 0.274, Rec: 0.235, F1: 0.253, Acc: 0.765\n",
      "Epoch: 21\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0483 - acc: 0.9822\n",
      "Test-Data: Prec: 0.286, Rec: 0.204, F1: 0.238, Acc: 0.779\n",
      "Epoch: 22\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0403 - acc: 0.9853\n",
      "Test-Data: Prec: 0.288, Rec: 0.173, F1: 0.217, Acc: 0.788\n",
      "Epoch: 23\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 216ms/step - loss: 0.0413 - acc: 0.9851\n",
      "Test-Data: Prec: 0.186, Rec: 0.112, F1: 0.140, Acc: 0.767\n",
      "Epoch: 24\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0408 - acc: 0.9848\n",
      "Test-Data: Prec: 0.274, Rec: 0.204, F1: 0.234, Acc: 0.774\n",
      "Epoch: 25\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0406 - acc: 0.9853\n",
      "Test-Data: Prec: 0.314, Rec: 0.224, F1: 0.262, Acc: 0.786\n",
      "Epoch: 26\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0339 - acc: 0.9872\n",
      "Test-Data: Prec: 0.269, Rec: 0.143, F1: 0.187, Acc: 0.789\n",
      "Epoch: 27\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0372 - acc: 0.9860\n",
      "Test-Data: Prec: 0.274, Rec: 0.173, F1: 0.212, Acc: 0.782\n",
      "Epoch: 28\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0243 - acc: 0.9912\n",
      "Test-Data: Prec: 0.250, Rec: 0.204, F1: 0.225, Acc: 0.762\n",
      "Epoch: 29\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0263 - acc: 0.9915\n",
      "Test-Data: Prec: 0.295, Rec: 0.184, F1: 0.226, Acc: 0.788\n",
      "Epoch: 30\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0331 - acc: 0.9875\n",
      "Test-Data: Prec: 0.275, Rec: 0.112, F1: 0.159, Acc: 0.800\n",
      "Epoch: 31\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.0239 - acc: 0.9908\n",
      "Test-Data: Prec: 0.255, Rec: 0.143, F1: 0.183, Acc: 0.784\n",
      "Epoch: 32\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0264 - acc: 0.9924\n",
      "Test-Data: Prec: 0.302, Rec: 0.133, F1: 0.184, Acc: 0.801\n",
      "Epoch: 33\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0251 - acc: 0.9898\n",
      "Test-Data: Prec: 0.306, Rec: 0.194, F1: 0.237, Acc: 0.789\n",
      "Epoch: 34\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0313 - acc: 0.9896\n",
      "Test-Data: Prec: 0.258, Rec: 0.082, F1: 0.124, Acc: 0.805\n",
      "Epoch: 35\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0279 - acc: 0.9905\n",
      "Test-Data: Prec: 0.267, Rec: 0.122, F1: 0.168, Acc: 0.794\n",
      "Epoch: 36\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0252 - acc: 0.9922\n",
      "Test-Data: Prec: 0.299, Rec: 0.235, F1: 0.263, Acc: 0.777\n",
      "Epoch: 37\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0231 - acc: 0.9915\n",
      "Test-Data: Prec: 0.265, Rec: 0.092, F1: 0.136, Acc: 0.803\n",
      "Epoch: 38\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0247 - acc: 0.9917\n",
      "Test-Data: Prec: 0.323, Rec: 0.214, F1: 0.258, Acc: 0.791\n",
      "Epoch: 39\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0226 - acc: 0.9927\n",
      "Test-Data: Prec: 0.286, Rec: 0.143, F1: 0.190, Acc: 0.794\n",
      "Epoch: 40\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0211 - acc: 0.9934\n",
      "Test-Data: Prec: 0.261, Rec: 0.184, F1: 0.216, Acc: 0.774\n",
      "Epoch: 41\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 214ms/step - loss: 0.0218 - acc: 0.9934\n",
      "Test-Data: Prec: 0.300, Rec: 0.184, F1: 0.228, Acc: 0.789\n",
      "Epoch: 42\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0220 - acc: 0.9920\n",
      "Test-Data: Prec: 0.313, Rec: 0.214, F1: 0.255, Acc: 0.788\n",
      "Epoch: 43\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0200 - acc: 0.9946\n",
      "Test-Data: Prec: 0.327, Rec: 0.163, F1: 0.218, Acc: 0.801\n",
      "Epoch: 44\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0170 - acc: 0.9941\n",
      "Test-Data: Prec: 0.316, Rec: 0.255, F1: 0.282, Acc: 0.781\n",
      "Epoch: 45\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 0.0181 - acc: 0.9920\n",
      "Test-Data: Prec: 0.306, Rec: 0.153, F1: 0.204, Acc: 0.798\n",
      "Epoch: 46\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0219 - acc: 0.9948\n",
      "Test-Data: Prec: 0.280, Rec: 0.143, F1: 0.189, Acc: 0.793\n",
      "Epoch: 47\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0190 - acc: 0.9936\n",
      "Test-Data: Prec: 0.323, Rec: 0.214, F1: 0.258, Acc: 0.791\n",
      "Epoch: 48\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0157 - acc: 0.9934\n",
      "Test-Data: Prec: 0.267, Rec: 0.122, F1: 0.168, Acc: 0.794\n",
      "Epoch: 49\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.0140 - acc: 0.9948\n",
      "Test-Data: Prec: 0.222, Rec: 0.102, F1: 0.140, Acc: 0.788\n",
      "Epoch: 50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0232 - acc: 0.9924\n",
      "Test-Data: Prec: 0.309, Rec: 0.173, F1: 0.222, Acc: 0.794\n",
      "*****************************************************************************\n",
      "Test 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 36s 272ms/step - loss: 0.4128 - acc: 0.8658\n",
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.831\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.3894 - acc: 0.8667\n",
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.827\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.3738 - acc: 0.8653\n",
      "Test-Data: Prec: 0.182, Rec: 0.020, F1: 0.037, Acc: 0.819\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.3623 - acc: 0.8667\n",
      "Test-Data: Prec: 0.143, Rec: 0.020, F1: 0.036, Acc: 0.813\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.3383 - acc: 0.8703\n",
      "Test-Data: Prec: 0.261, Rec: 0.061, F1: 0.099, Acc: 0.812\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.3151 - acc: 0.8759\n",
      "Test-Data: Prec: 0.233, Rec: 0.071, F1: 0.109, Acc: 0.803\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.2844 - acc: 0.8875\n",
      "Test-Data: Prec: 0.246, Rec: 0.306, F1: 0.273, Acc: 0.724\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.2604 - acc: 0.8975\n",
      "Test-Data: Prec: 0.292, Rec: 0.143, F1: 0.192, Acc: 0.796\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.2251 - acc: 0.9084\n",
      "Test-Data: Prec: 0.270, Rec: 0.245, F1: 0.257, Acc: 0.760\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.2066 - acc: 0.9195\n",
      "Test-Data: Prec: 0.265, Rec: 0.133, F1: 0.177, Acc: 0.791\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.1840 - acc: 0.9278\n",
      "Test-Data: Prec: 0.333, Rec: 0.133, F1: 0.190, Acc: 0.808\n",
      "Epoch: 12\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.1600 - acc: 0.9382\n",
      "Test-Data: Prec: 0.282, Rec: 0.112, F1: 0.161, Acc: 0.801\n",
      "Epoch: 13\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.1433 - acc: 0.9403\n",
      "Test-Data: Prec: 0.244, Rec: 0.102, F1: 0.144, Acc: 0.794\n",
      "Epoch: 14\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.1275 - acc: 0.9503\n",
      "Test-Data: Prec: 0.276, Rec: 0.082, F1: 0.126, Acc: 0.808\n",
      "Epoch: 15\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.1018 - acc: 0.9621\n",
      "Test-Data: Prec: 0.191, Rec: 0.092, F1: 0.124, Acc: 0.781\n",
      "Epoch: 16\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.1000 - acc: 0.9628\n",
      "Test-Data: Prec: 0.271, Rec: 0.133, F1: 0.178, Acc: 0.793\n",
      "Epoch: 17\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0828 - acc: 0.9680\n",
      "Test-Data: Prec: 0.227, Rec: 0.102, F1: 0.141, Acc: 0.789\n",
      "Epoch: 18\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.1308 - acc: 0.9621\n",
      "Test-Data: Prec: 0.179, Rec: 0.102, F1: 0.130, Acc: 0.769\n",
      "Epoch: 19\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0770 - acc: 0.9735\n",
      "Test-Data: Prec: 0.271, Rec: 0.194, F1: 0.226, Acc: 0.775\n",
      "Epoch: 20\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0604 - acc: 0.9787\n",
      "Test-Data: Prec: 0.209, Rec: 0.092, F1: 0.128, Acc: 0.788\n",
      "Epoch: 21\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0610 - acc: 0.9789\n",
      "Test-Data: Prec: 0.230, Rec: 0.143, F1: 0.176, Acc: 0.774\n",
      "Epoch: 22\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0507 - acc: 0.9830\n",
      "Test-Data: Prec: 0.282, Rec: 0.204, F1: 0.237, Acc: 0.777\n",
      "Epoch: 23\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0329 - acc: 0.9882\n",
      "Test-Data: Prec: 0.176, Rec: 0.061, F1: 0.091, Acc: 0.793\n",
      "Epoch: 24\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0419 - acc: 0.9844\n",
      "Test-Data: Prec: 0.286, Rec: 0.184, F1: 0.224, Acc: 0.784\n",
      "Epoch: 25\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0348 - acc: 0.9893\n",
      "Test-Data: Prec: 0.233, Rec: 0.102, F1: 0.142, Acc: 0.791\n",
      "Epoch: 26\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0287 - acc: 0.9910\n",
      "Test-Data: Prec: 0.196, Rec: 0.092, F1: 0.125, Acc: 0.782\n",
      "Epoch: 27\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.0365 - acc: 0.9860\n",
      "Test-Data: Prec: 0.091, Rec: 0.031, F1: 0.046, Acc: 0.784\n",
      "Epoch: 28\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0285 - acc: 0.9917\n",
      "Test-Data: Prec: 0.240, Rec: 0.122, F1: 0.162, Acc: 0.786\n",
      "Epoch: 29\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0292 - acc: 0.9922\n",
      "Test-Data: Prec: 0.273, Rec: 0.184, F1: 0.220, Acc: 0.779\n",
      "Epoch: 30\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0294 - acc: 0.9910\n",
      "Test-Data: Prec: 0.239, Rec: 0.163, F1: 0.194, Acc: 0.770\n",
      "Epoch: 31\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0299 - acc: 0.9891\n",
      "Test-Data: Prec: 0.275, Rec: 0.194, F1: 0.228, Acc: 0.777\n",
      "Epoch: 32\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0306 - acc: 0.9884\n",
      "Test-Data: Prec: 0.268, Rec: 0.194, F1: 0.225, Acc: 0.774\n",
      "Epoch: 33\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0242 - acc: 0.9920\n",
      "Test-Data: Prec: 0.188, Rec: 0.061, F1: 0.092, Acc: 0.796\n",
      "Epoch: 34\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0286 - acc: 0.9891\n",
      "Test-Data: Prec: 0.207, Rec: 0.061, F1: 0.094, Acc: 0.801\n",
      "Epoch: 35\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0306 - acc: 0.9896\n",
      "Test-Data: Prec: 0.237, Rec: 0.092, F1: 0.132, Acc: 0.796\n",
      "Epoch: 36\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0253 - acc: 0.9915\n",
      "Test-Data: Prec: 0.289, Rec: 0.112, F1: 0.162, Acc: 0.803\n",
      "Epoch: 37\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0361 - acc: 0.9870\n",
      "Test-Data: Prec: 0.283, Rec: 0.133, F1: 0.181, Acc: 0.796\n",
      "Epoch: 38\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 228ms/step - loss: 0.0172 - acc: 0.9931\n",
      "Test-Data: Prec: 0.263, Rec: 0.102, F1: 0.147, Acc: 0.800\n",
      "Epoch: 39\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0202 - acc: 0.9905\n",
      "Test-Data: Prec: 0.158, Rec: 0.031, F1: 0.051, Acc: 0.808\n",
      "Epoch: 40\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.0200 - acc: 0.9915\n",
      "Test-Data: Prec: 0.333, Rec: 0.184, F1: 0.237, Acc: 0.800\n",
      "Epoch: 41\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.0233 - acc: 0.9922\n",
      "Test-Data: Prec: 0.265, Rec: 0.133, F1: 0.177, Acc: 0.791\n",
      "Epoch: 42\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0248 - acc: 0.9936\n",
      "Test-Data: Prec: 0.242, Rec: 0.082, F1: 0.122, Acc: 0.801\n",
      "Epoch: 43\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0139 - acc: 0.9953\n",
      "Test-Data: Prec: 0.235, Rec: 0.082, F1: 0.121, Acc: 0.800\n",
      "Epoch: 44\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0142 - acc: 0.9943\n",
      "Test-Data: Prec: 0.235, Rec: 0.082, F1: 0.121, Acc: 0.800\n",
      "Epoch: 45\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0152 - acc: 0.9946\n",
      "Test-Data: Prec: 0.243, Rec: 0.092, F1: 0.133, Acc: 0.798\n",
      "Epoch: 46\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 216ms/step - loss: 0.0176 - acc: 0.9950\n",
      "Test-Data: Prec: 0.234, Rec: 0.112, F1: 0.152, Acc: 0.788\n",
      "Epoch: 47\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0206 - acc: 0.9920\n",
      "Test-Data: Prec: 0.288, Rec: 0.214, F1: 0.246, Acc: 0.777\n",
      "Epoch: 48\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0211 - acc: 0.9934\n",
      "Test-Data: Prec: 0.293, Rec: 0.122, F1: 0.173, Acc: 0.801\n",
      "Epoch: 49\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0175 - acc: 0.9934\n",
      "Test-Data: Prec: 0.192, Rec: 0.102, F1: 0.133, Acc: 0.775\n",
      "Epoch: 50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 231ms/step - loss: 0.0158 - acc: 0.9938\n",
      "Test-Data: Prec: 0.176, Rec: 0.061, F1: 0.091, Acc: 0.793\n",
      "*****************************************************************************\n",
      "Test 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 35s 268ms/step - loss: 0.4089 - acc: 0.8629\n",
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.831\n",
      "Epoch: 2\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.3866 - acc: 0.8665\n",
      "Test-Data: Prec: 0.000, Rec: 0.000, F1: 0.000, Acc: 0.831\n",
      "Epoch: 3\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.3749 - acc: 0.8660\n",
      "Test-Data: Prec: 0.500, Rec: 0.010, F1: 0.020, Acc: 0.831\n",
      "Epoch: 4\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.3632 - acc: 0.8681\n",
      "Test-Data: Prec: 0.333, Rec: 0.020, F1: 0.038, Acc: 0.827\n",
      "Epoch: 5\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.3402 - acc: 0.8686\n",
      "Test-Data: Prec: 0.156, Rec: 0.051, F1: 0.077, Acc: 0.793\n",
      "Epoch: 6\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.3183 - acc: 0.8783\n",
      "Test-Data: Prec: 0.253, Rec: 0.224, F1: 0.238, Acc: 0.756\n",
      "Epoch: 7\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 0.2824 - acc: 0.8868\n",
      "Test-Data: Prec: 0.211, Rec: 0.163, F1: 0.184, Acc: 0.755\n",
      "Epoch: 8\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 0.2464 - acc: 0.9013\n",
      "Test-Data: Prec: 0.225, Rec: 0.235, F1: 0.230, Acc: 0.734\n",
      "Epoch: 9\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.2234 - acc: 0.9103\n",
      "Test-Data: Prec: 0.261, Rec: 0.184, F1: 0.216, Acc: 0.774\n",
      "Epoch: 10\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.1969 - acc: 0.9261\n",
      "Test-Data: Prec: 0.250, Rec: 0.173, F1: 0.205, Acc: 0.772\n",
      "Epoch: 11\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.1708 - acc: 0.9328\n",
      "Test-Data: Prec: 0.227, Rec: 0.153, F1: 0.183, Acc: 0.769\n",
      "Epoch: 12\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.1581 - acc: 0.9380\n",
      "Test-Data: Prec: 0.237, Rec: 0.143, F1: 0.178, Acc: 0.777\n",
      "Epoch: 13\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.1430 - acc: 0.9425\n",
      "Test-Data: Prec: 0.250, Rec: 0.102, F1: 0.145, Acc: 0.796\n",
      "Epoch: 14\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.1237 - acc: 0.9529\n",
      "Test-Data: Prec: 0.208, Rec: 0.214, F1: 0.211, Acc: 0.729\n",
      "Epoch: 15\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.1140 - acc: 0.9543\n",
      "Test-Data: Prec: 0.253, Rec: 0.214, F1: 0.232, Acc: 0.760\n",
      "Epoch: 16\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0918 - acc: 0.9661\n",
      "Test-Data: Prec: 0.200, Rec: 0.112, F1: 0.144, Acc: 0.774\n",
      "Epoch: 17\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0830 - acc: 0.9666\n",
      "Test-Data: Prec: 0.255, Rec: 0.133, F1: 0.174, Acc: 0.788\n",
      "Epoch: 18\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 229ms/step - loss: 0.0700 - acc: 0.9732\n",
      "Test-Data: Prec: 0.306, Rec: 0.194, F1: 0.237, Acc: 0.789\n",
      "Epoch: 19\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0576 - acc: 0.9785\n",
      "Test-Data: Prec: 0.233, Rec: 0.143, F1: 0.177, Acc: 0.775\n",
      "Epoch: 20\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.0617 - acc: 0.9763\n",
      "Test-Data: Prec: 0.241, Rec: 0.133, F1: 0.171, Acc: 0.782\n",
      "Epoch: 21\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0511 - acc: 0.9830\n",
      "Test-Data: Prec: 0.282, Rec: 0.224, F1: 0.250, Acc: 0.772\n",
      "Epoch: 22\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.0439 - acc: 0.9830\n",
      "Test-Data: Prec: 0.243, Rec: 0.184, F1: 0.209, Acc: 0.765\n",
      "Epoch: 23\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0432 - acc: 0.9837\n",
      "Test-Data: Prec: 0.196, Rec: 0.112, F1: 0.143, Acc: 0.772\n",
      "Epoch: 24\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.0408 - acc: 0.9834\n",
      "Test-Data: Prec: 0.275, Rec: 0.112, F1: 0.159, Acc: 0.800\n",
      "Epoch: 25\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0341 - acc: 0.9882\n",
      "Test-Data: Prec: 0.229, Rec: 0.082, F1: 0.120, Acc: 0.798\n",
      "Epoch: 26\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0334 - acc: 0.9875\n",
      "Test-Data: Prec: 0.269, Rec: 0.143, F1: 0.187, Acc: 0.789\n",
      "Epoch: 27\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0287 - acc: 0.9889\n",
      "Test-Data: Prec: 0.327, Rec: 0.173, F1: 0.227, Acc: 0.800\n",
      "Epoch: 28\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0280 - acc: 0.9901\n",
      "Test-Data: Prec: 0.246, Rec: 0.163, F1: 0.196, Acc: 0.774\n",
      "Epoch: 29\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0366 - acc: 0.9879\n",
      "Test-Data: Prec: 0.226, Rec: 0.122, F1: 0.159, Acc: 0.781\n",
      "Epoch: 30\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0243 - acc: 0.9908\n",
      "Test-Data: Prec: 0.225, Rec: 0.092, F1: 0.130, Acc: 0.793\n",
      "Epoch: 31\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0305 - acc: 0.9882\n",
      "Test-Data: Prec: 0.200, Rec: 0.082, F1: 0.116, Acc: 0.789\n",
      "Epoch: 32\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0350 - acc: 0.9886\n",
      "Test-Data: Prec: 0.235, Rec: 0.122, F1: 0.161, Acc: 0.784\n",
      "Epoch: 33\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0259 - acc: 0.9915\n",
      "Test-Data: Prec: 0.196, Rec: 0.112, F1: 0.143, Acc: 0.772\n",
      "Epoch: 34\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 216ms/step - loss: 0.0235 - acc: 0.9910\n",
      "Test-Data: Prec: 0.257, Rec: 0.184, F1: 0.214, Acc: 0.772\n",
      "Epoch: 35\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0218 - acc: 0.9920\n",
      "Test-Data: Prec: 0.200, Rec: 0.102, F1: 0.135, Acc: 0.779\n",
      "Epoch: 36\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0174 - acc: 0.9941\n",
      "Test-Data: Prec: 0.241, Rec: 0.194, F1: 0.215, Acc: 0.760\n",
      "Epoch: 37\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 220ms/step - loss: 0.0215 - acc: 0.9924\n",
      "Test-Data: Prec: 0.211, Rec: 0.122, F1: 0.155, Acc: 0.774\n",
      "Epoch: 38\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0251 - acc: 0.9920\n",
      "Test-Data: Prec: 0.214, Rec: 0.092, F1: 0.129, Acc: 0.789\n",
      "Epoch: 39\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 219ms/step - loss: 0.0287 - acc: 0.9917\n",
      "Test-Data: Prec: 0.242, Rec: 0.163, F1: 0.195, Acc: 0.772\n",
      "Epoch: 40\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0218 - acc: 0.9927\n",
      "Test-Data: Prec: 0.295, Rec: 0.184, F1: 0.226, Acc: 0.788\n",
      "Epoch: 41\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0177 - acc: 0.9943\n",
      "Test-Data: Prec: 0.224, Rec: 0.133, F1: 0.167, Acc: 0.775\n",
      "Epoch: 42\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0195 - acc: 0.9929\n",
      "Test-Data: Prec: 0.278, Rec: 0.102, F1: 0.149, Acc: 0.803\n",
      "Epoch: 43\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 221ms/step - loss: 0.0132 - acc: 0.9948\n",
      "Test-Data: Prec: 0.267, Rec: 0.082, F1: 0.125, Acc: 0.807\n",
      "Epoch: 44\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0153 - acc: 0.9929\n",
      "Test-Data: Prec: 0.314, Rec: 0.112, F1: 0.165, Acc: 0.808\n",
      "Epoch: 45\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 28s 215ms/step - loss: 0.0201 - acc: 0.9927\n",
      "Test-Data: Prec: 0.279, Rec: 0.122, F1: 0.170, Acc: 0.798\n",
      "Epoch: 46\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0170 - acc: 0.9938\n",
      "Test-Data: Prec: 0.291, Rec: 0.163, F1: 0.209, Acc: 0.791\n",
      "Epoch: 47\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0173 - acc: 0.9950\n",
      "Test-Data: Prec: 0.280, Rec: 0.071, F1: 0.114, Acc: 0.812\n",
      "Epoch: 48\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 218ms/step - loss: 0.0234 - acc: 0.9924\n",
      "Test-Data: Prec: 0.288, Rec: 0.153, F1: 0.200, Acc: 0.793\n",
      "Epoch: 49\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0146 - acc: 0.9962\n",
      "Test-Data: Prec: 0.300, Rec: 0.153, F1: 0.203, Acc: 0.796\n",
      "Epoch: 50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 217ms/step - loss: 0.0150 - acc: 0.9953\n",
      "Test-Data: Prec: 0.263, Rec: 0.153, F1: 0.194, Acc: 0.784\n",
      "*****************************************************************************\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary +: 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-23262425a320>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_to_log\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmillion_pos_corpus_pretraining_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_to_save_weigths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmillionpostcorpus_pretraining_save_weigths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmillionpostcorpus_train_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_measure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf1_measure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_model_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           nb_sequence_length=nb_sequence_length, nb_embedding_dims=nb_embedding_dims, check_for_generator= check_for_generator)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-644aa135bf66>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(generator, train_sentences, devLabels, number_of_tests, number_of_epochs, filename_to_log, filename_to_save_weigths, batch_size, train_file, f1_measure, pos_label, load_model_weights, model_weights_file, nb_sequence_length, nb_embedding_dims, check_for_generator)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*****************************************************************************\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mfinal_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"avg_prec: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_prec\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_of_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" total_rec: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_recall\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_of_tests\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" total_f1: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_f1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_of_tests\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\" total_acc: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_acc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_of_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary +: 'str'"
     ]
    }
   ],
   "source": [
    "test_model(generator=generator, \n",
    "           train_sentences=train_sentences, \n",
    "           devLabels=devLabels, \n",
    "           number_of_tests= number_of_tests,\n",
    "           number_of_epochs=number_of_epochs, \n",
    "           filename_to_log=millionpostcorpus_pretraining_log, \n",
    "           labels_earlier = len(labels2Idx),\n",
    "           filename_to_save_weigths=millionpostcorpus_pretraining_save_weigths,\n",
    "           batch_size=batch_size,\n",
    "           train_file=millionpostcorpus_train_file, \n",
    "           f1_measure=f1_measure, \n",
    "           pos_label=pos_label, \n",
    "           load_model_weights=load_model_weights,\n",
    "           tokenize = tokenize,\n",
    "           nb_sequence_length=nb_sequence_length, \n",
    "           nb_embedding_dims=nb_embedding_dims, \n",
    "           check_for_generator= check_for_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradual_unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels, dev_sentences, dev_labels, labels2Idx = train_dev_sentences(filetrain='/home/gwiedemann/notebooks/OffLang/sample_train.txt',\n",
    "                   filedev='/home/gwiedemann/notebooks/OffLang/sample_dev.txt', check=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@FilmElf_yt Diese ganzen leute die du angesprochen hast sind untermenschen ja aber das alte Deutschland und deutsche volk waren ehrenwerte leute und ein stolzes Land\n",
      "808\n",
      "808\n",
      "{'ABUSE': 3, 'PROFANITY': 2, 'INSULT': 1, 'OTHER': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dev_sentences[0])\n",
    "print(len(dev_sentences))\n",
    "print(len(dev_labels))\n",
    "print(labels2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_tl_unfreezing(generator, \n",
    "               train_sentences, \n",
    "               devLabels, \n",
    "               number_of_tests,\n",
    "               number_of_epochs,\n",
    "               filename_to_log, \n",
    "               labels2Idx,\n",
    "               filename_to_save_weigths,\n",
    "               batch_size, \n",
    "               unfreezing_strategy: 'list containing a tuple of indices to unfreeze at each step',\n",
    "               train_file:'filepath for traininig',\n",
    "               f1_measure:'binary/macro etc', \n",
    "               pos_label:'only if binary f1',\n",
    "               load_model_weights=False,\n",
    "               model_weights_file:'give filepath as str'=None, \n",
    "               tokenize=True,\n",
    "               nb_sequence_length = nb_sequence_length,\n",
    "               nb_embedding_dims= nb_embedding_dims, \n",
    "               check_for_generator=None):\n",
    "    \n",
    "    f = open(filename_to_log, 'w', encoding='utf-8')\n",
    "    f.close()\n",
    "    \n",
    "   \n",
    "    total_f1=0\n",
    "    total_prec=0\n",
    "    total_acc=0\n",
    "    total_recall=0\n",
    "    \n",
    "    for test_number in range(number_of_tests):\n",
    "        print(\"Test %d/%d\" %(test_number+1, number_of_tests))\n",
    "        model = compile_model(2)\n",
    "\n",
    "        # transfer learning\n",
    "        if load_model_weights and model_weights_file:\n",
    "                model.load_weights(model_weights_file)\n",
    "                print(\"removing top layer\")\n",
    "                model.layers.pop()\n",
    "                output = Dense(len(labels2Idx), activation = 'softmax')(model.layers[-1].output)\n",
    "                final_model = Model(inputs=model.input, outputs=[output])\n",
    "\n",
    "        samples_per_epoch = len(train_sentences)\n",
    "        epochs = number_of_epochs\n",
    "        batch_size = batch_size\n",
    "        steps_per_epoch = math.ceil(samples_per_epoch / batch_size)\n",
    "#         checkpoint = ModelCheckpoint(filename_to_save_weigths, monitor='val_acc',save_best_only = True, \n",
    "#                                      save_weights_only = True)\n",
    "\n",
    "\n",
    "        max_f1=0\n",
    "        max_p=0\n",
    "        max_r=0\n",
    "        max_a=0\n",
    "        \n",
    "        # load pretrained weights\n",
    "        # model.compile\n",
    "        # save tmp weights\n",
    "        # iterate over layers\n",
    "        #    load tmp weights\n",
    "        #    iterate over epochs\n",
    "        #        unfreeze top frozen layer\n",
    "        #        save best model as tmp weights\n",
    "        \n",
    "        \n",
    "        final_model.save(filename_to_save_weigths)\n",
    "        \n",
    "        # layers_to_unfreeze = [18, 16, 3, 1]\n",
    "        \n",
    "        for ulayer in unfreezing_strategy:\n",
    "            print(\"unfreezing \" + final_model.layers[ulayer[0]].name)\n",
    "            print(\"---------------------------------------\")\n",
    "            final_model.load_weights(filename_to_save_weigths)            \n",
    "            for i, layer in enumerate(final_model.layers):\n",
    "                \n",
    "                # TF strategy: gradual unfreezing\n",
    "                #if i >= ulayer:\n",
    "                #    layer.trainable = True\n",
    "                #else:\n",
    "                #    layer.trainable = False\n",
    "                # \n",
    "                ## TF strategy: single\n",
    "                \n",
    "                if i >= ulayer[1] and i <= ulayer[0]:\n",
    "                    layer.trainable = True\n",
    "                else:\n",
    "                    layer.trainable = False\n",
    "                    \n",
    "                print(str(i) + ' ' + layer.name + ' ' + str(layer.trainable))\n",
    "            final_model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        \n",
    "            for epoch in range(epochs):\n",
    "                print(\"Epoch: %d/%d\" %(epoch+1, epochs))\n",
    "                final_model.fit_generator(\n",
    "                    generator(filename = train_file, batch_size = batch_size, check = check_for_generator, \n",
    "                              labels2Idx= labels2Idx,tokenize= tokenize), \n",
    "                    steps_per_epoch= steps_per_epoch, epochs=1\n",
    "                )\n",
    "\n",
    "                testset_features = np.zeros((len(dev_sentences), nb_sequence_length, nb_embedding_dims))\n",
    "                for i in range(len(dev_sentences)):\n",
    "                    testset_features[i] = process_features(dev_sentences[i], nb_sequence_length, nb_embedding_dims)\n",
    "                results = final_model.predict(testset_features)\n",
    "\n",
    "                predLabels = results.argmax(axis=-1)\n",
    "                devLabels = devLabels\n",
    "                f1 = f1_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label) # offensive is the major class. So other is minor\n",
    "                r = recall_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label)\n",
    "                p = precision_score(devLabels, predLabels, average=f1_measure, pos_label=pos_label)\n",
    "                a = accuracy_score(devLabels, predLabels)\n",
    "                if max_f1 < f1:\n",
    "                    print(\"model saved. F1 is %f\" %(f1))\n",
    "                    final_model.save(filename_to_save_weigths)\n",
    "                    max_f1 = f1\n",
    "                    max_p = p\n",
    "                    max_r = r\n",
    "                    max_a = a\n",
    "                text = \"prec: \"+ str(p)+\" rec: \"+str(r) +\" f1: \"+str(f1) +\" acc: \"+str(a)+\" \\n\"\n",
    "                print(\"Test-Data: Prec: %.3f, Rec: %.3f, F1: %.3f, Acc: %.3f\" % (p, r, f1, a))\n",
    "        to_write= \"prec: \"+ str(max_p)+\" rec: \"+str(max_r) +\" f1: \"+str(max_f1) +\" acc: \"+str(max_a)+\" \\n\"\n",
    "        print(to_write)\n",
    "        with open(filename_to_log,'a') as f:\n",
    "            f.write(to_write)\n",
    "        total_f1+=max_f1\n",
    "        total_prec+=max_p\n",
    "        total_acc+=max_a\n",
    "        total_recall+=max_r    \n",
    "        print(\"*****************************************************************************\")\n",
    "    final_text = \"avg_prec: \" +str(total_prec/number_of_tests)+\" total_rec: \"+str(total_recall/number_of_tests) +\" total_f1: \"+str(total_f1/number_of_tests) +\" total_acc: \"+str(total_acc/number_of_tests)+\" \\n\"\n",
    "    print(final_text)\n",
    "    with open(filename_to_log,'a') as f:\n",
    "        f.write(final_text)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tuples. Every tuple contains range of layers which need to be unfrozen. Rest all are frozen\n",
    "single_unfreeze_bottom_up = [(18, 18), (17, 16), (15, 3), (2, 1), (18,1)] \n",
    "single_unfreeze_top_down = [(18, 18),   (2, 1),(15, 3), (17, 16), (18,1)]\n",
    "all_unfreeze = [(18,1)]\n",
    "gradual_unfreezing = [(18,18), (18,16), (18,3), (18,1)]\n",
    "\n",
    "strings =['suf_bu', 'suf_td','all_unfreeze','gradual_unfreeze']\n",
    "# strings=['gradual_unfreeze']\n",
    "unfreeze_strategy = [single_unfreeze_bottom_up, single_unfreeze_top_down, all_unfreeze, gradual_unfreezing]\n",
    "# unfreeze_strategy = [gradual_unfreezing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approach: suf_bu\n",
      "log file: /home/jindal/notebooks/jindal/NER/language_model/results_tl_millionpostcorpus_t2_suf_bu.txt\n",
      "save weights file: /home/jindal/notebooks/jindal/NER/language_model/classification_model_tl_millionpostcorpus_t2_suf_bu.h5\n",
      "[(18, 18), (17, 16), (15, 3), (2, 1), (18, 1)]\n",
      "Test 1/5\n",
      "removing top layer\n",
      "unfreezing dense_99\n",
      "---------------------------------------\n",
      "0 input_33 False\n",
      "1 bidirectional_33 False\n",
      "2 leaky_re_lu_161 False\n",
      "3 conv1d_97 False\n",
      "4 conv1d_98 False\n",
      "5 conv1d_99 False\n",
      "6 leaky_re_lu_162 False\n",
      "7 leaky_re_lu_163 False\n",
      "8 leaky_re_lu_164 False\n",
      "9 global_max_pooling1d_97 False\n",
      "10 global_max_pooling1d_98 False\n",
      "11 global_max_pooling1d_99 False\n",
      "12 dropout_97 False\n",
      "13 dropout_98 False\n",
      "14 dropout_99 False\n",
      "15 concatenate_33 False\n",
      "16 dense_97 False\n",
      "17 leaky_re_lu_165 False\n",
      "18 dense_99 True\n",
      "Epoch: 1/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 20s 150ms/step - loss: 0.9977 - acc: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved. F1 is 0.200149\n",
      "Test-Data: Prec: 0.167, Rec: 0.249, F1: 0.200, Acc: 0.666\n",
      "Epoch: 2/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.9296 - acc: 0.6610\n",
      "model saved. F1 is 0.200668\n",
      "Test-Data: Prec: 0.168, Rec: 0.250, F1: 0.201, Acc: 0.670\n",
      "Epoch: 3/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.9118 - acc: 0.6619\n",
      "Test-Data: Prec: 0.167, Rec: 0.250, F1: 0.201, Acc: 0.670\n",
      "Epoch: 4/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.9005 - acc: 0.6626\n",
      "Test-Data: Prec: 0.167, Rec: 0.249, F1: 0.200, Acc: 0.666\n",
      "Epoch: 5/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.9004 - acc: 0.6598\n",
      "model saved. F1 is 0.211802\n",
      "Test-Data: Prec: 0.279, Rec: 0.254, F1: 0.212, Acc: 0.670\n",
      "Epoch: 6/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8998 - acc: 0.6626\n",
      "model saved. F1 is 0.214199\n",
      "Test-Data: Prec: 0.282, Rec: 0.255, F1: 0.214, Acc: 0.668\n",
      "Epoch: 7/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8966 - acc: 0.6600\n",
      "Test-Data: Prec: 0.262, Rec: 0.253, F1: 0.209, Acc: 0.668\n",
      "Epoch: 8/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8950 - acc: 0.6584\n",
      "Test-Data: Prec: 0.268, Rec: 0.254, F1: 0.212, Acc: 0.668\n",
      "Epoch: 9/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8883 - acc: 0.6624\n",
      "model saved. F1 is 0.216984\n",
      "Test-Data: Prec: 0.284, Rec: 0.256, F1: 0.217, Acc: 0.670\n",
      "Epoch: 10/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8857 - acc: 0.6631\n",
      "Test-Data: Prec: 0.264, Rec: 0.254, F1: 0.214, Acc: 0.667\n",
      "Epoch: 11/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8897 - acc: 0.6624\n",
      "Test-Data: Prec: 0.272, Rec: 0.255, F1: 0.214, Acc: 0.668\n",
      "Epoch: 12/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8851 - acc: 0.6619\n",
      "Test-Data: Prec: 0.268, Rec: 0.252, F1: 0.206, Acc: 0.670\n",
      "Epoch: 13/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8862 - acc: 0.6624\n",
      "Test-Data: Prec: 0.268, Rec: 0.252, F1: 0.206, Acc: 0.668\n",
      "Epoch: 14/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8816 - acc: 0.6579\n",
      "model saved. F1 is 0.219501\n",
      "Test-Data: Prec: 0.365, Rec: 0.257, F1: 0.220, Acc: 0.668\n",
      "Epoch: 15/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8880 - acc: 0.6586\n",
      "Test-Data: Prec: 0.356, Rec: 0.257, F1: 0.219, Acc: 0.667\n",
      "Epoch: 16/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8833 - acc: 0.6629\n",
      "Test-Data: Prec: 0.262, Rec: 0.255, F1: 0.216, Acc: 0.667\n",
      "Epoch: 17/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8860 - acc: 0.6617\n",
      "model saved. F1 is 0.227354\n",
      "Test-Data: Prec: 0.377, Rec: 0.261, F1: 0.227, Acc: 0.670\n",
      "Epoch: 18/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8784 - acc: 0.6626\n",
      "Test-Data: Prec: 0.274, Rec: 0.258, F1: 0.222, Acc: 0.668\n",
      "Epoch: 19/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8823 - acc: 0.6617\n",
      "Test-Data: Prec: 0.377, Rec: 0.261, F1: 0.227, Acc: 0.670\n",
      "Epoch: 20/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8774 - acc: 0.6657\n",
      "Test-Data: Prec: 0.369, Rec: 0.260, F1: 0.227, Acc: 0.668\n",
      "Epoch: 21/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8759 - acc: 0.6612\n",
      "Test-Data: Prec: 0.272, Rec: 0.254, F1: 0.214, Acc: 0.667\n",
      "Epoch: 22/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8764 - acc: 0.6619\n",
      "Test-Data: Prec: 0.397, Rec: 0.257, F1: 0.219, Acc: 0.668\n",
      "Epoch: 23/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8743 - acc: 0.6612\n",
      "model saved. F1 is 0.229474\n",
      "Test-Data: Prec: 0.356, Rec: 0.261, F1: 0.229, Acc: 0.668\n",
      "Epoch: 24/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 9s 71ms/step - loss: 0.8794 - acc: 0.6624\n",
      "Test-Data: Prec: 0.389, Rec: 0.257, F1: 0.219, Acc: 0.667\n",
      "Epoch: 25/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8784 - acc: 0.6643\n",
      "model saved. F1 is 0.231548\n",
      "Test-Data: Prec: 0.338, Rec: 0.262, F1: 0.232, Acc: 0.667\n",
      "Epoch: 26/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.8789 - acc: 0.6610\n",
      "Test-Data: Prec: 0.361, Rec: 0.259, F1: 0.224, Acc: 0.667\n",
      "Epoch: 27/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.8780 - acc: 0.6570\n",
      "Test-Data: Prec: 0.274, Rec: 0.257, F1: 0.221, Acc: 0.667\n",
      "Epoch: 28/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8731 - acc: 0.6629\n",
      "model saved. F1 is 0.232392\n",
      "Test-Data: Prec: 0.419, Rec: 0.263, F1: 0.232, Acc: 0.671\n",
      "Epoch: 29/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8772 - acc: 0.6636\n",
      "model saved. F1 is 0.233906\n",
      "Test-Data: Prec: 0.290, Rec: 0.264, F1: 0.234, Acc: 0.671\n",
      "Epoch: 30/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8761 - acc: 0.6624\n",
      "model saved. F1 is 0.238104\n",
      "Test-Data: Prec: 0.431, Rec: 0.267, F1: 0.238, Acc: 0.675\n",
      "Epoch: 31/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8780 - acc: 0.6619\n",
      "Test-Data: Prec: 0.285, Rec: 0.257, F1: 0.219, Acc: 0.668\n",
      "Epoch: 32/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8732 - acc: 0.6615\n",
      "Test-Data: Prec: 0.400, Rec: 0.258, F1: 0.222, Acc: 0.668\n",
      "Epoch: 33/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8779 - acc: 0.6655\n",
      "Test-Data: Prec: 0.400, Rec: 0.258, F1: 0.222, Acc: 0.668\n",
      "Epoch: 34/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8738 - acc: 0.6641\n",
      "model saved. F1 is 0.241383\n",
      "Test-Data: Prec: 0.378, Rec: 0.267, F1: 0.241, Acc: 0.671\n",
      "Epoch: 35/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8725 - acc: 0.6636\n",
      "Test-Data: Prec: 0.403, Rec: 0.260, F1: 0.225, Acc: 0.670\n",
      "Epoch: 36/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8717 - acc: 0.6636\n",
      "Test-Data: Prec: 0.363, Rec: 0.260, F1: 0.227, Acc: 0.668\n",
      "Epoch: 37/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8748 - acc: 0.6648\n",
      "Test-Data: Prec: 0.412, Rec: 0.261, F1: 0.228, Acc: 0.671\n",
      "Epoch: 38/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8784 - acc: 0.6586\n",
      "Test-Data: Prec: 0.419, Rec: 0.264, F1: 0.233, Acc: 0.672\n",
      "Epoch: 39/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8761 - acc: 0.6636\n",
      "model saved. F1 is 0.241513\n",
      "Test-Data: Prec: 0.362, Rec: 0.267, F1: 0.242, Acc: 0.671\n",
      "Epoch: 40/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8687 - acc: 0.6626\n",
      "Test-Data: Prec: 0.412, Rec: 0.262, F1: 0.230, Acc: 0.671\n",
      "Epoch: 41/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8794 - acc: 0.6589\n",
      "model saved. F1 is 0.242213\n",
      "Test-Data: Prec: 0.388, Rec: 0.268, F1: 0.242, Acc: 0.673\n",
      "Epoch: 42/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.8756 - acc: 0.6593\n",
      "Test-Data: Prec: 0.400, Rec: 0.258, F1: 0.222, Acc: 0.668\n",
      "Epoch: 43/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8809 - acc: 0.6612\n",
      "Test-Data: Prec: 0.346, Rec: 0.267, F1: 0.241, Acc: 0.670\n",
      "Epoch: 44/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8742 - acc: 0.6643\n",
      "Test-Data: Prec: 0.412, Rec: 0.262, F1: 0.230, Acc: 0.671\n",
      "Epoch: 45/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8759 - acc: 0.6612\n",
      "Test-Data: Prec: 0.410, Rec: 0.260, F1: 0.225, Acc: 0.670\n",
      "Epoch: 46/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8736 - acc: 0.6648\n",
      "Test-Data: Prec: 0.425, Rec: 0.265, F1: 0.235, Acc: 0.673\n",
      "Epoch: 47/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 72ms/step - loss: 0.8743 - acc: 0.6657\n",
      "Test-Data: Prec: 0.431, Rec: 0.267, F1: 0.238, Acc: 0.675\n",
      "Epoch: 48/50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8773 - acc: 0.6598\n",
      "Test-Data: Prec: 0.400, Rec: 0.258, F1: 0.222, Acc: 0.668\n",
      "Epoch: 49/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.8715 - acc: 0.6645\n",
      "Test-Data: Prec: 0.419, Rec: 0.262, F1: 0.230, Acc: 0.671\n",
      "Epoch: 50/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8757 - acc: 0.6612\n",
      "Test-Data: Prec: 0.294, Rec: 0.261, F1: 0.227, Acc: 0.671\n",
      "unfreezing leaky_re_lu_165\n",
      "---------------------------------------\n",
      "0 input_33 False\n",
      "1 bidirectional_33 False\n",
      "2 leaky_re_lu_161 False\n",
      "3 conv1d_97 False\n",
      "4 conv1d_98 False\n",
      "5 conv1d_99 False\n",
      "6 leaky_re_lu_162 False\n",
      "7 leaky_re_lu_163 False\n",
      "8 leaky_re_lu_164 False\n",
      "9 global_max_pooling1d_97 False\n",
      "10 global_max_pooling1d_98 False\n",
      "11 global_max_pooling1d_99 False\n",
      "12 dropout_97 False\n",
      "13 dropout_98 False\n",
      "14 dropout_99 False\n",
      "15 concatenate_33 False\n",
      "16 dense_97 True\n",
      "17 leaky_re_lu_165 True\n",
      "18 dense_99 False\n",
      "Epoch: 1/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 19s 145ms/step - loss: 0.8852 - acc: 0.6589\n",
      "Test-Data: Prec: 0.306, Rec: 0.265, F1: 0.233, Acc: 0.676\n",
      "Epoch: 2/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8713 - acc: 0.6629\n",
      "model saved. F1 is 0.244225\n",
      "Test-Data: Prec: 0.462, Rec: 0.271, F1: 0.244, Acc: 0.679\n",
      "Epoch: 3/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8730 - acc: 0.6570\n",
      "Test-Data: Prec: 0.315, Rec: 0.269, F1: 0.240, Acc: 0.678\n",
      "Epoch: 4/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8716 - acc: 0.6589\n",
      "model saved. F1 is 0.252462\n",
      "Test-Data: Prec: 0.309, Rec: 0.275, F1: 0.252, Acc: 0.678\n",
      "Epoch: 5/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8623 - acc: 0.6629\n",
      "Test-Data: Prec: 0.309, Rec: 0.275, F1: 0.252, Acc: 0.677\n",
      "Epoch: 6/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8666 - acc: 0.6581\n",
      "Test-Data: Prec: 0.323, Rec: 0.275, F1: 0.252, Acc: 0.682\n",
      "Epoch: 7/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8513 - acc: 0.6681\n",
      "model saved. F1 is 0.276075\n",
      "Test-Data: Prec: 0.339, Rec: 0.291, F1: 0.276, Acc: 0.693\n",
      "Epoch: 8/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8688 - acc: 0.6562\n",
      "Test-Data: Prec: 0.449, Rec: 0.273, F1: 0.248, Acc: 0.679\n",
      "Epoch: 9/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8659 - acc: 0.6610\n",
      "Test-Data: Prec: 0.394, Rec: 0.276, F1: 0.254, Acc: 0.682\n",
      "Epoch: 10/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8588 - acc: 0.6626\n",
      "Test-Data: Prec: 0.451, Rec: 0.282, F1: 0.265, Acc: 0.683\n",
      "Epoch: 11/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8567 - acc: 0.6643\n",
      "Test-Data: Prec: 0.404, Rec: 0.279, F1: 0.263, Acc: 0.677\n",
      "Epoch: 12/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8485 - acc: 0.6712\n",
      "Test-Data: Prec: 0.568, Rec: 0.277, F1: 0.257, Acc: 0.681\n",
      "Epoch: 13/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8566 - acc: 0.6593\n",
      "model saved. F1 is 0.282840\n",
      "Test-Data: Prec: 0.330, Rec: 0.295, F1: 0.283, Acc: 0.691\n",
      "Epoch: 14/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8578 - acc: 0.6662\n",
      "Test-Data: Prec: 0.315, Rec: 0.273, F1: 0.249, Acc: 0.678\n",
      "Epoch: 15/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8608 - acc: 0.6624\n",
      "Test-Data: Prec: 0.316, Rec: 0.272, F1: 0.247, Acc: 0.677\n",
      "Epoch: 16/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8534 - acc: 0.6645\n",
      "Test-Data: Prec: 0.313, Rec: 0.276, F1: 0.253, Acc: 0.679\n",
      "Epoch: 17/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8590 - acc: 0.6607\n",
      "Test-Data: Prec: 0.316, Rec: 0.277, F1: 0.255, Acc: 0.681\n",
      "Epoch: 18/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8564 - acc: 0.6629\n",
      "Test-Data: Prec: 0.580, Rec: 0.277, F1: 0.256, Acc: 0.683\n",
      "Epoch: 19/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8563 - acc: 0.6622\n",
      "Test-Data: Prec: 0.320, Rec: 0.283, F1: 0.264, Acc: 0.684\n",
      "Epoch: 20/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8640 - acc: 0.6584\n",
      "Test-Data: Prec: 0.557, Rec: 0.274, F1: 0.251, Acc: 0.677\n",
      "Epoch: 21/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8542 - acc: 0.6622\n",
      "Test-Data: Prec: 0.310, Rec: 0.274, F1: 0.251, Acc: 0.678\n",
      "Epoch: 22/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8477 - acc: 0.6671\n",
      "Test-Data: Prec: 0.319, Rec: 0.289, F1: 0.274, Acc: 0.686\n",
      "Epoch: 23/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.8575 - acc: 0.6610\n",
      "Test-Data: Prec: 0.450, Rec: 0.280, F1: 0.262, Acc: 0.683\n",
      "Epoch: 24/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8474 - acc: 0.6652\n",
      "Test-Data: Prec: 0.569, Rec: 0.276, F1: 0.255, Acc: 0.681\n",
      "Epoch: 25/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8466 - acc: 0.6593\n",
      "Test-Data: Prec: 0.369, Rec: 0.285, F1: 0.273, Acc: 0.678\n",
      "Epoch: 26/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8592 - acc: 0.6626\n",
      "Test-Data: Prec: 0.309, Rec: 0.275, F1: 0.254, Acc: 0.676\n",
      "Epoch: 27/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8542 - acc: 0.6617\n",
      "Test-Data: Prec: 0.393, Rec: 0.286, F1: 0.276, Acc: 0.677\n",
      "Epoch: 28/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8592 - acc: 0.6589\n",
      "Test-Data: Prec: 0.320, Rec: 0.277, F1: 0.256, Acc: 0.681\n",
      "Epoch: 29/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8681 - acc: 0.6598\n",
      "Test-Data: Prec: 0.406, Rec: 0.280, F1: 0.263, Acc: 0.681\n",
      "Epoch: 30/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8586 - acc: 0.6634\n",
      "Test-Data: Prec: 0.328, Rec: 0.270, F1: 0.245, Acc: 0.675\n",
      "Epoch: 31/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8509 - acc: 0.6652\n",
      "Test-Data: Prec: 0.424, Rec: 0.282, F1: 0.264, Acc: 0.684\n",
      "Epoch: 32/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8454 - acc: 0.6650\n",
      "Test-Data: Prec: 0.444, Rec: 0.272, F1: 0.248, Acc: 0.678\n",
      "Epoch: 33/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8604 - acc: 0.6581\n",
      "Test-Data: Prec: 0.398, Rec: 0.282, F1: 0.270, Acc: 0.676\n",
      "Epoch: 34/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8611 - acc: 0.6562\n",
      "Test-Data: Prec: 0.353, Rec: 0.280, F1: 0.264, Acc: 0.677\n",
      "Epoch: 35/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8591 - acc: 0.6664\n",
      "Test-Data: Prec: 0.309, Rec: 0.277, F1: 0.255, Acc: 0.679\n",
      "Epoch: 36/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8542 - acc: 0.6674\n",
      "Test-Data: Prec: 0.566, Rec: 0.280, F1: 0.261, Acc: 0.682\n",
      "Epoch: 37/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8605 - acc: 0.6603\n",
      "Test-Data: Prec: 0.553, Rec: 0.276, F1: 0.255, Acc: 0.677\n",
      "Epoch: 38/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8547 - acc: 0.6603\n",
      "Test-Data: Prec: 0.438, Rec: 0.285, F1: 0.269, Acc: 0.681\n",
      "Epoch: 39/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8478 - acc: 0.6645\n",
      "Test-Data: Prec: 0.313, Rec: 0.277, F1: 0.255, Acc: 0.679\n",
      "Epoch: 40/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8489 - acc: 0.6681\n",
      "Test-Data: Prec: 0.422, Rec: 0.284, F1: 0.270, Acc: 0.682\n",
      "Epoch: 41/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8446 - acc: 0.6664\n",
      "Test-Data: Prec: 0.299, Rec: 0.270, F1: 0.243, Acc: 0.675\n",
      "Epoch: 42/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8589 - acc: 0.6586\n",
      "Test-Data: Prec: 0.316, Rec: 0.279, F1: 0.258, Acc: 0.682\n",
      "Epoch: 43/50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8545 - acc: 0.6617\n",
      "Test-Data: Prec: 0.312, Rec: 0.272, F1: 0.247, Acc: 0.679\n",
      "Epoch: 44/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8571 - acc: 0.6581\n",
      "Test-Data: Prec: 0.431, Rec: 0.291, F1: 0.278, Acc: 0.684\n",
      "Epoch: 45/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8551 - acc: 0.6626\n",
      "Test-Data: Prec: 0.316, Rec: 0.278, F1: 0.256, Acc: 0.682\n",
      "Epoch: 46/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.8539 - acc: 0.6589\n",
      "Test-Data: Prec: 0.303, Rec: 0.274, F1: 0.251, Acc: 0.678\n",
      "Epoch: 47/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 74ms/step - loss: 0.8502 - acc: 0.6615\n",
      "Test-Data: Prec: 0.316, Rec: 0.279, F1: 0.258, Acc: 0.683\n",
      "Epoch: 48/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.8587 - acc: 0.6650\n",
      "Test-Data: Prec: 0.322, Rec: 0.287, F1: 0.270, Acc: 0.688\n",
      "Epoch: 49/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 75ms/step - loss: 0.8503 - acc: 0.6681\n",
      "Test-Data: Prec: 0.338, Rec: 0.293, F1: 0.278, Acc: 0.694\n",
      "Epoch: 50/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 73ms/step - loss: 0.8425 - acc: 0.6643\n",
      "Test-Data: Prec: 0.574, Rec: 0.286, F1: 0.270, Acc: 0.687\n",
      "unfreezing concatenate_33\n",
      "---------------------------------------\n",
      "0 input_33 False\n",
      "1 bidirectional_33 False\n",
      "2 leaky_re_lu_161 False\n",
      "3 conv1d_97 True\n",
      "4 conv1d_98 True\n",
      "5 conv1d_99 True\n",
      "6 leaky_re_lu_162 True\n",
      "7 leaky_re_lu_163 True\n",
      "8 leaky_re_lu_164 True\n",
      "9 global_max_pooling1d_97 True\n",
      "10 global_max_pooling1d_98 True\n",
      "11 global_max_pooling1d_99 True\n",
      "12 dropout_97 True\n",
      "13 dropout_98 True\n",
      "14 dropout_99 True\n",
      "15 concatenate_33 True\n",
      "16 dense_97 False\n",
      "17 leaky_re_lu_165 False\n",
      "18 dense_99 False\n",
      "Epoch: 1/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 20s 152ms/step - loss: 0.8619 - acc: 0.6612\n",
      "Test-Data: Prec: 0.417, Rec: 0.289, F1: 0.276, Acc: 0.686\n",
      "Epoch: 2/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.8056 - acc: 0.6830\n",
      "model saved. F1 is 0.323677\n",
      "Test-Data: Prec: 0.397, Rec: 0.322, F1: 0.324, Acc: 0.704\n",
      "Epoch: 3/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.7978 - acc: 0.6785\n",
      "model saved. F1 is 0.341015\n",
      "Test-Data: Prec: 0.419, Rec: 0.333, F1: 0.341, Acc: 0.704\n",
      "Epoch: 4/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.7761 - acc: 0.6967\n",
      "Test-Data: Prec: 0.414, Rec: 0.325, F1: 0.328, Acc: 0.708\n",
      "Epoch: 5/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.7449 - acc: 0.7003\n",
      "model saved. F1 is 0.365963\n",
      "Test-Data: Prec: 0.426, Rec: 0.352, F1: 0.366, Acc: 0.704\n",
      "Epoch: 6/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.7280 - acc: 0.7036\n",
      "model saved. F1 is 0.370917\n",
      "Test-Data: Prec: 0.453, Rec: 0.356, F1: 0.371, Acc: 0.718\n",
      "Epoch: 7/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.7159 - acc: 0.7164\n",
      "Test-Data: Prec: 0.408, Rec: 0.350, F1: 0.360, Acc: 0.702\n",
      "Epoch: 8/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.6977 - acc: 0.7124\n",
      "Test-Data: Prec: 0.430, Rec: 0.349, F1: 0.360, Acc: 0.715\n",
      "Epoch: 9/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.6951 - acc: 0.7131\n",
      "model saved. F1 is 0.403589\n",
      "Test-Data: Prec: 0.680, Rec: 0.375, F1: 0.404, Acc: 0.715\n",
      "Epoch: 10/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.6760 - acc: 0.7259\n",
      "Test-Data: Prec: 0.451, Rec: 0.379, F1: 0.396, Acc: 0.723\n",
      "Epoch: 11/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.6556 - acc: 0.7386\n",
      "model saved. F1 is 0.415272\n",
      "Test-Data: Prec: 0.552, Rec: 0.386, F1: 0.415, Acc: 0.712\n",
      "Epoch: 12/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.6536 - acc: 0.7422\n",
      "model saved. F1 is 0.416264\n",
      "Test-Data: Prec: 0.520, Rec: 0.391, F1: 0.416, Acc: 0.717\n",
      "Epoch: 13/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.6356 - acc: 0.7410\n",
      "Test-Data: Prec: 0.534, Rec: 0.378, F1: 0.404, Acc: 0.724\n",
      "Epoch: 14/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.6198 - acc: 0.7562\n",
      "Test-Data: Prec: 0.691, Rec: 0.376, F1: 0.409, Acc: 0.715\n",
      "Epoch: 15/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.6232 - acc: 0.7464\n",
      "Test-Data: Prec: 0.554, Rec: 0.389, F1: 0.416, Acc: 0.714\n",
      "Epoch: 16/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.6052 - acc: 0.7635\n",
      "model saved. F1 is 0.434098\n",
      "Test-Data: Prec: 0.564, Rec: 0.405, F1: 0.434, Acc: 0.718\n",
      "Epoch: 17/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.5951 - acc: 0.7602\n",
      "Test-Data: Prec: 0.574, Rec: 0.397, F1: 0.423, Acc: 0.718\n",
      "Epoch: 18/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.5764 - acc: 0.7758\n",
      "model saved. F1 is 0.441465\n",
      "Test-Data: Prec: 0.597, Rec: 0.408, F1: 0.441, Acc: 0.729\n",
      "Epoch: 19/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.5740 - acc: 0.7753\n",
      "Test-Data: Prec: 0.583, Rec: 0.407, F1: 0.441, Acc: 0.724\n",
      "Epoch: 20/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.5697 - acc: 0.7801\n",
      "model saved. F1 is 0.441499\n",
      "Test-Data: Prec: 0.546, Rec: 0.412, F1: 0.441, Acc: 0.733\n",
      "Epoch: 21/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.5525 - acc: 0.7749\n",
      "model saved. F1 is 0.453816\n",
      "Test-Data: Prec: 0.544, Rec: 0.425, F1: 0.454, Acc: 0.731\n",
      "Epoch: 22/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.5337 - acc: 0.7886\n",
      "Test-Data: Prec: 0.579, Rec: 0.413, F1: 0.443, Acc: 0.725\n",
      "Epoch: 23/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.5351 - acc: 0.7850\n",
      "Test-Data: Prec: 0.507, Rec: 0.408, F1: 0.433, Acc: 0.720\n",
      "Epoch: 24/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.5462 - acc: 0.7796\n",
      "Test-Data: Prec: 0.573, Rec: 0.405, F1: 0.437, Acc: 0.723\n",
      "Epoch: 25/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.5198 - acc: 0.7959\n",
      "Test-Data: Prec: 0.558, Rec: 0.400, F1: 0.430, Acc: 0.717\n",
      "Epoch: 26/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.5100 - acc: 0.8004\n",
      "Test-Data: Prec: 0.526, Rec: 0.369, F1: 0.392, Acc: 0.715\n",
      "Epoch: 27/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.5066 - acc: 0.8026\n",
      "Test-Data: Prec: 0.536, Rec: 0.414, F1: 0.444, Acc: 0.725\n",
      "Epoch: 28/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.5075 - acc: 0.7988\n",
      "Test-Data: Prec: 0.504, Rec: 0.417, F1: 0.442, Acc: 0.718\n",
      "Epoch: 29/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.4792 - acc: 0.8120\n",
      "Test-Data: Prec: 0.494, Rec: 0.399, F1: 0.422, Acc: 0.715\n",
      "Epoch: 30/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4754 - acc: 0.8127\n",
      "Test-Data: Prec: 0.490, Rec: 0.399, F1: 0.423, Acc: 0.714\n",
      "Epoch: 31/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.4738 - acc: 0.8120\n",
      "Test-Data: Prec: 0.492, Rec: 0.394, F1: 0.419, Acc: 0.720\n",
      "Epoch: 32/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4665 - acc: 0.8161\n",
      "model saved. F1 is 0.457241\n",
      "Test-Data: Prec: 0.506, Rec: 0.433, F1: 0.457, Acc: 0.726\n",
      "Epoch: 33/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.4523 - acc: 0.8279\n",
      "Test-Data: Prec: 0.492, Rec: 0.383, F1: 0.408, Acc: 0.707\n",
      "Epoch: 34/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.4495 - acc: 0.8243\n",
      "Test-Data: Prec: 0.488, Rec: 0.397, F1: 0.420, Acc: 0.712\n",
      "Epoch: 35/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.4659 - acc: 0.8179\n",
      "Test-Data: Prec: 0.501, Rec: 0.384, F1: 0.409, Acc: 0.715\n",
      "Epoch: 36/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4353 - acc: 0.8279\n",
      "Test-Data: Prec: 0.482, Rec: 0.404, F1: 0.426, Acc: 0.713\n",
      "Epoch: 37/50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 10s 78ms/step - loss: 0.4295 - acc: 0.8288\n",
      "Test-Data: Prec: 0.493, Rec: 0.401, F1: 0.420, Acc: 0.717\n",
      "Epoch: 38/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.4301 - acc: 0.8362\n",
      "Test-Data: Prec: 0.582, Rec: 0.414, F1: 0.447, Acc: 0.725\n",
      "Epoch: 39/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 78ms/step - loss: 0.4144 - acc: 0.8393\n",
      "Test-Data: Prec: 0.514, Rec: 0.388, F1: 0.415, Acc: 0.714\n",
      "Epoch: 40/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.4198 - acc: 0.8388\n",
      "Test-Data: Prec: 0.519, Rec: 0.410, F1: 0.439, Acc: 0.724\n",
      "Epoch: 41/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 80ms/step - loss: 0.4138 - acc: 0.8397\n",
      "Test-Data: Prec: 0.511, Rec: 0.410, F1: 0.436, Acc: 0.725\n",
      "Epoch: 42/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.4165 - acc: 0.8414\n",
      "Test-Data: Prec: 0.499, Rec: 0.402, F1: 0.426, Acc: 0.722\n",
      "Epoch: 43/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.4025 - acc: 0.8433\n",
      "Test-Data: Prec: 0.519, Rec: 0.382, F1: 0.407, Acc: 0.713\n",
      "Epoch: 44/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 79ms/step - loss: 0.3978 - acc: 0.8456\n",
      "Test-Data: Prec: 0.512, Rec: 0.421, F1: 0.445, Acc: 0.725\n",
      "Epoch: 45/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.3978 - acc: 0.8445\n",
      "Test-Data: Prec: 0.450, Rec: 0.377, F1: 0.389, Acc: 0.720\n",
      "Epoch: 46/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 81ms/step - loss: 0.3963 - acc: 0.8480\n",
      "Test-Data: Prec: 0.486, Rec: 0.399, F1: 0.421, Acc: 0.714\n",
      "Epoch: 47/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 11s 82ms/step - loss: 0.3705 - acc: 0.8572\n",
      "Test-Data: Prec: 0.518, Rec: 0.406, F1: 0.432, Acc: 0.723\n",
      "Epoch: 48/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.3801 - acc: 0.8511\n",
      "Test-Data: Prec: 0.511, Rec: 0.407, F1: 0.432, Acc: 0.723\n",
      "Epoch: 49/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 76ms/step - loss: 0.3630 - acc: 0.8622\n",
      "Test-Data: Prec: 0.491, Rec: 0.379, F1: 0.404, Acc: 0.710\n",
      "Epoch: 50/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 10s 77ms/step - loss: 0.3633 - acc: 0.8622\n",
      "Test-Data: Prec: 0.514, Rec: 0.397, F1: 0.424, Acc: 0.719\n",
      "unfreezing leaky_re_lu_161\n",
      "---------------------------------------\n",
      "0 input_33 False\n",
      "1 bidirectional_33 True\n",
      "2 leaky_re_lu_161 True\n",
      "3 conv1d_97 False\n",
      "4 conv1d_98 False\n",
      "5 conv1d_99 False\n",
      "6 leaky_re_lu_162 False\n",
      "7 leaky_re_lu_163 False\n",
      "8 leaky_re_lu_164 False\n",
      "9 global_max_pooling1d_97 False\n",
      "10 global_max_pooling1d_98 False\n",
      "11 global_max_pooling1d_99 False\n",
      "12 dropout_97 False\n",
      "13 dropout_98 False\n",
      "14 dropout_99 False\n",
      "15 concatenate_33 False\n",
      "16 dense_97 False\n",
      "17 leaky_re_lu_165 False\n",
      "18 dense_99 False\n",
      "Epoch: 1/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 41s 308ms/step - loss: 0.4561 - acc: 0.8227\n",
      "model saved. F1 is 0.474035\n",
      "Test-Data: Prec: 0.549, Rec: 0.443, F1: 0.474, Acc: 0.739\n",
      "Epoch: 2/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.3932 - acc: 0.8475\n",
      "Test-Data: Prec: 0.510, Rec: 0.436, F1: 0.460, Acc: 0.735\n",
      "Epoch: 3/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 0.3516 - acc: 0.8629\n",
      "model saved. F1 is 0.482151\n",
      "Test-Data: Prec: 0.529, Rec: 0.457, F1: 0.482, Acc: 0.754\n",
      "Epoch: 4/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.3249 - acc: 0.8764\n",
      "model saved. F1 is 0.504494\n",
      "Test-Data: Prec: 0.540, Rec: 0.483, F1: 0.504, Acc: 0.751\n",
      "Epoch: 5/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.2965 - acc: 0.8823\n",
      "Test-Data: Prec: 0.604, Rec: 0.447, F1: 0.481, Acc: 0.749\n",
      "Epoch: 6/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.2896 - acc: 0.8861\n",
      "model saved. F1 is 0.506273\n",
      "Test-Data: Prec: 0.534, Rec: 0.489, F1: 0.506, Acc: 0.751\n",
      "Epoch: 7/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 0.2615 - acc: 0.9022\n",
      "Test-Data: Prec: 0.538, Rec: 0.454, F1: 0.482, Acc: 0.759\n",
      "Epoch: 8/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.2434 - acc: 0.9055\n",
      "Test-Data: Prec: 0.521, Rec: 0.447, F1: 0.472, Acc: 0.748\n",
      "Epoch: 9/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.2317 - acc: 0.9103\n",
      "Test-Data: Prec: 0.520, Rec: 0.474, F1: 0.492, Acc: 0.751\n",
      "Epoch: 10/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.2154 - acc: 0.9200\n",
      "model saved. F1 is 0.523684\n",
      "Test-Data: Prec: 0.535, Rec: 0.514, F1: 0.524, Acc: 0.749\n",
      "Epoch: 11/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.2075 - acc: 0.9197\n",
      "Test-Data: Prec: 0.527, Rec: 0.476, F1: 0.495, Acc: 0.751\n",
      "Epoch: 12/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 229ms/step - loss: 0.1906 - acc: 0.9297\n",
      "Test-Data: Prec: 0.532, Rec: 0.438, F1: 0.466, Acc: 0.750\n",
      "Epoch: 13/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 242ms/step - loss: 0.1890 - acc: 0.9287\n",
      "Test-Data: Prec: 0.527, Rec: 0.434, F1: 0.461, Acc: 0.749\n",
      "Epoch: 14/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 0.1806 - acc: 0.9302\n",
      "Test-Data: Prec: 0.525, Rec: 0.453, F1: 0.476, Acc: 0.752\n",
      "Epoch: 15/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 240ms/step - loss: 0.1656 - acc: 0.9375\n",
      "Test-Data: Prec: 0.607, Rec: 0.475, F1: 0.500, Acc: 0.761\n",
      "Epoch: 16/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 226ms/step - loss: 0.1668 - acc: 0.9380\n",
      "Test-Data: Prec: 0.574, Rec: 0.486, F1: 0.517, Acc: 0.752\n",
      "Epoch: 17/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 33s 249ms/step - loss: 0.1644 - acc: 0.9441\n",
      "Test-Data: Prec: 0.553, Rec: 0.468, F1: 0.496, Acc: 0.748\n",
      "Epoch: 18/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 241ms/step - loss: 0.1431 - acc: 0.9510\n",
      "Test-Data: Prec: 0.576, Rec: 0.473, F1: 0.507, Acc: 0.756\n",
      "Epoch: 19/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.1458 - acc: 0.9486\n",
      "Test-Data: Prec: 0.561, Rec: 0.477, F1: 0.507, Acc: 0.755\n",
      "Epoch: 20/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.1435 - acc: 0.9491\n",
      "Test-Data: Prec: 0.552, Rec: 0.466, F1: 0.487, Acc: 0.745\n",
      "Epoch: 21/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.1305 - acc: 0.9510\n",
      "Test-Data: Prec: 0.538, Rec: 0.465, F1: 0.488, Acc: 0.751\n",
      "Epoch: 22/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 229ms/step - loss: 0.1294 - acc: 0.9548\n",
      "Test-Data: Prec: 0.525, Rec: 0.462, F1: 0.484, Acc: 0.745\n",
      "Epoch: 23/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 238ms/step - loss: 0.1247 - acc: 0.9541\n",
      "Test-Data: Prec: 0.611, Rec: 0.468, F1: 0.499, Acc: 0.760\n",
      "Epoch: 24/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 237ms/step - loss: 0.1271 - acc: 0.9560\n",
      "Test-Data: Prec: 0.550, Rec: 0.447, F1: 0.477, Acc: 0.754\n",
      "Epoch: 25/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 246ms/step - loss: 0.1130 - acc: 0.9567\n",
      "Test-Data: Prec: 0.568, Rec: 0.477, F1: 0.509, Acc: 0.755\n",
      "Epoch: 26/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 245ms/step - loss: 0.1074 - acc: 0.9628\n",
      "Test-Data: Prec: 0.572, Rec: 0.467, F1: 0.496, Acc: 0.759\n",
      "Epoch: 27/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.1212 - acc: 0.9562\n",
      "Test-Data: Prec: 0.535, Rec: 0.464, F1: 0.486, Acc: 0.751\n",
      "Epoch: 28/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 229ms/step - loss: 0.1123 - acc: 0.9612\n",
      "Test-Data: Prec: 0.577, Rec: 0.469, F1: 0.501, Acc: 0.766\n",
      "Epoch: 29/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1010 - acc: 0.9624\n",
      "Test-Data: Prec: 0.727, Rec: 0.448, F1: 0.480, Acc: 0.751\n",
      "Epoch: 30/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.1040 - acc: 0.9635\n",
      "Test-Data: Prec: 0.532, Rec: 0.462, F1: 0.487, Acc: 0.752\n",
      "Epoch: 31/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0844 - acc: 0.9732\n",
      "Test-Data: Prec: 0.619, Rec: 0.458, F1: 0.492, Acc: 0.759\n",
      "Epoch: 32/50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 30s 229ms/step - loss: 0.0885 - acc: 0.9685\n",
      "Test-Data: Prec: 0.535, Rec: 0.461, F1: 0.484, Acc: 0.748\n",
      "Epoch: 33/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 0.1005 - acc: 0.9633\n",
      "Test-Data: Prec: 0.558, Rec: 0.463, F1: 0.487, Acc: 0.749\n",
      "Epoch: 34/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.0950 - acc: 0.9685\n",
      "Test-Data: Prec: 0.569, Rec: 0.487, F1: 0.509, Acc: 0.761\n",
      "Epoch: 35/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.0929 - acc: 0.9669\n",
      "Test-Data: Prec: 0.547, Rec: 0.475, F1: 0.500, Acc: 0.760\n",
      "Epoch: 36/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 0.0860 - acc: 0.9688\n",
      "Test-Data: Prec: 0.559, Rec: 0.456, F1: 0.485, Acc: 0.760\n",
      "Epoch: 37/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 33s 247ms/step - loss: 0.0931 - acc: 0.9671\n",
      "Test-Data: Prec: 0.535, Rec: 0.467, F1: 0.489, Acc: 0.745\n",
      "Epoch: 38/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 245ms/step - loss: 0.0816 - acc: 0.9723\n",
      "Test-Data: Prec: 0.545, Rec: 0.454, F1: 0.481, Acc: 0.751\n",
      "Epoch: 39/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.0827 - acc: 0.9725\n",
      "Test-Data: Prec: 0.608, Rec: 0.476, F1: 0.503, Acc: 0.752\n",
      "Epoch: 40/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.0754 - acc: 0.9709\n",
      "Test-Data: Prec: 0.540, Rec: 0.475, F1: 0.495, Acc: 0.752\n",
      "Epoch: 41/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0843 - acc: 0.9709\n",
      "Test-Data: Prec: 0.586, Rec: 0.457, F1: 0.483, Acc: 0.746\n",
      "Epoch: 42/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.0855 - acc: 0.9676\n",
      "Test-Data: Prec: 0.539, Rec: 0.472, F1: 0.494, Acc: 0.760\n",
      "Epoch: 43/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0756 - acc: 0.9749\n",
      "Test-Data: Prec: 0.533, Rec: 0.469, F1: 0.492, Acc: 0.759\n",
      "Epoch: 44/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0801 - acc: 0.9725\n",
      "Test-Data: Prec: 0.547, Rec: 0.472, F1: 0.495, Acc: 0.760\n",
      "Epoch: 45/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 244ms/step - loss: 0.0641 - acc: 0.9770\n",
      "Test-Data: Prec: 0.540, Rec: 0.479, F1: 0.500, Acc: 0.760\n",
      "Epoch: 46/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 224ms/step - loss: 0.0665 - acc: 0.9756\n",
      "Test-Data: Prec: 0.538, Rec: 0.454, F1: 0.482, Acc: 0.754\n",
      "Epoch: 47/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.0722 - acc: 0.9761\n",
      "Test-Data: Prec: 0.570, Rec: 0.478, F1: 0.502, Acc: 0.760\n",
      "Epoch: 48/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 0.0681 - acc: 0.9735\n",
      "Test-Data: Prec: 0.566, Rec: 0.475, F1: 0.500, Acc: 0.760\n",
      "Epoch: 49/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.0790 - acc: 0.9732\n",
      "Test-Data: Prec: 0.516, Rec: 0.463, F1: 0.480, Acc: 0.751\n",
      "Epoch: 50/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.0672 - acc: 0.9759\n",
      "Test-Data: Prec: 0.529, Rec: 0.460, F1: 0.480, Acc: 0.750\n",
      "unfreezing dense_99\n",
      "---------------------------------------\n",
      "0 input_33 False\n",
      "1 bidirectional_33 True\n",
      "2 leaky_re_lu_161 True\n",
      "3 conv1d_97 True\n",
      "4 conv1d_98 True\n",
      "5 conv1d_99 True\n",
      "6 leaky_re_lu_162 True\n",
      "7 leaky_re_lu_163 True\n",
      "8 leaky_re_lu_164 True\n",
      "9 global_max_pooling1d_97 True\n",
      "10 global_max_pooling1d_98 True\n",
      "11 global_max_pooling1d_99 True\n",
      "12 dropout_97 True\n",
      "13 dropout_98 True\n",
      "14 dropout_99 True\n",
      "15 concatenate_33 True\n",
      "16 dense_97 True\n",
      "17 leaky_re_lu_165 True\n",
      "18 dense_99 True\n",
      "Epoch: 1/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 43s 327ms/step - loss: 0.2654 - acc: 0.9008\n",
      "model saved. F1 is 0.533769\n",
      "Test-Data: Prec: 0.545, Rec: 0.527, F1: 0.534, Acc: 0.745\n",
      "Epoch: 2/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 236ms/step - loss: 0.2403 - acc: 0.9096\n",
      "Test-Data: Prec: 0.556, Rec: 0.508, F1: 0.528, Acc: 0.755\n",
      "Epoch: 3/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 230ms/step - loss: 0.2327 - acc: 0.9093\n",
      "Test-Data: Prec: 0.583, Rec: 0.485, F1: 0.518, Acc: 0.744\n",
      "Epoch: 4/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.2196 - acc: 0.9131\n",
      "Test-Data: Prec: 0.606, Rec: 0.499, F1: 0.532, Acc: 0.755\n",
      "Epoch: 5/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1914 - acc: 0.9287\n",
      "Test-Data: Prec: 0.583, Rec: 0.488, F1: 0.522, Acc: 0.743\n",
      "Epoch: 6/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1718 - acc: 0.9347\n",
      "Test-Data: Prec: 0.559, Rec: 0.484, F1: 0.507, Acc: 0.746\n",
      "Epoch: 7/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1729 - acc: 0.9366\n",
      "Test-Data: Prec: 0.549, Rec: 0.485, F1: 0.508, Acc: 0.743\n",
      "Epoch: 8/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.1649 - acc: 0.9382\n",
      "Test-Data: Prec: 0.579, Rec: 0.495, F1: 0.524, Acc: 0.759\n",
      "Epoch: 9/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 0.1422 - acc: 0.9467\n",
      "Test-Data: Prec: 0.553, Rec: 0.480, F1: 0.507, Acc: 0.740\n",
      "Epoch: 10/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.1391 - acc: 0.9474\n",
      "Test-Data: Prec: 0.720, Rec: 0.490, F1: 0.508, Acc: 0.741\n",
      "Epoch: 11/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 229ms/step - loss: 0.1277 - acc: 0.9541\n",
      "Test-Data: Prec: 0.602, Rec: 0.439, F1: 0.473, Acc: 0.749\n",
      "Epoch: 12/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.1158 - acc: 0.9583\n",
      "Test-Data: Prec: 0.611, Rec: 0.466, F1: 0.496, Acc: 0.750\n",
      "Epoch: 13/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 225ms/step - loss: 0.1274 - acc: 0.9543\n",
      "Test-Data: Prec: 0.508, Rec: 0.488, F1: 0.494, Acc: 0.738\n",
      "Epoch: 14/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.1090 - acc: 0.9588\n",
      "model saved. F1 is 0.535612\n",
      "Test-Data: Prec: 0.646, Rec: 0.499, F1: 0.536, Acc: 0.749\n",
      "Epoch: 15/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.1093 - acc: 0.9590\n",
      "Test-Data: Prec: 0.543, Rec: 0.463, F1: 0.490, Acc: 0.755\n",
      "Epoch: 16/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 0.1097 - acc: 0.9602\n",
      "Test-Data: Prec: 0.538, Rec: 0.480, F1: 0.498, Acc: 0.743\n",
      "Epoch: 17/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 231ms/step - loss: 0.1052 - acc: 0.9602\n",
      "Test-Data: Prec: 0.737, Rec: 0.482, F1: 0.508, Acc: 0.751\n",
      "Epoch: 18/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 222ms/step - loss: 0.0991 - acc: 0.9628\n",
      "Test-Data: Prec: 0.545, Rec: 0.488, F1: 0.506, Acc: 0.730\n",
      "Epoch: 19/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 29s 223ms/step - loss: 0.0830 - acc: 0.9695\n",
      "Test-Data: Prec: 0.567, Rec: 0.446, F1: 0.479, Acc: 0.748\n",
      "Epoch: 20/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.0978 - acc: 0.9692\n",
      "Test-Data: Prec: 0.564, Rec: 0.475, F1: 0.505, Acc: 0.750\n",
      "Epoch: 21/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 231ms/step - loss: 0.0799 - acc: 0.9678\n",
      "Test-Data: Prec: 0.715, Rec: 0.457, F1: 0.484, Acc: 0.744\n",
      "Epoch: 22/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 232ms/step - loss: 0.1014 - acc: 0.9664\n",
      "Test-Data: Prec: 0.526, Rec: 0.467, F1: 0.490, Acc: 0.738\n",
      "Epoch: 23/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 30s 227ms/step - loss: 0.0733 - acc: 0.9754\n",
      "Test-Data: Prec: 0.591, Rec: 0.471, F1: 0.494, Acc: 0.745\n",
      "Epoch: 24/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 233ms/step - loss: 0.0890 - acc: 0.9666\n",
      "Test-Data: Prec: 0.574, Rec: 0.462, F1: 0.494, Acc: 0.757\n",
      "Epoch: 25/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 235ms/step - loss: 0.0885 - acc: 0.9690\n",
      "Test-Data: Prec: 0.550, Rec: 0.433, F1: 0.465, Acc: 0.754\n",
      "Epoch: 26/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 231ms/step - loss: 0.0801 - acc: 0.9711\n",
      "model saved. F1 is 0.567660\n",
      "Test-Data: Prec: 0.632, Rec: 0.535, F1: 0.568, Acc: 0.774\n",
      "Epoch: 27/50\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 30s 230ms/step - loss: 0.0791 - acc: 0.9721\n",
      "Test-Data: Prec: 0.555, Rec: 0.484, F1: 0.511, Acc: 0.743\n",
      "Epoch: 28/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 238ms/step - loss: 0.0667 - acc: 0.9740\n",
      "Test-Data: Prec: 0.565, Rec: 0.478, F1: 0.507, Acc: 0.745\n",
      "Epoch: 29/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 239ms/step - loss: 0.0868 - acc: 0.9702\n",
      "Test-Data: Prec: 0.724, Rec: 0.461, F1: 0.489, Acc: 0.749\n",
      "Epoch: 30/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 243ms/step - loss: 0.0730 - acc: 0.9747\n",
      "Test-Data: Prec: 0.554, Rec: 0.463, F1: 0.488, Acc: 0.748\n",
      "Epoch: 31/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 32s 240ms/step - loss: 0.0522 - acc: 0.9820\n",
      "Test-Data: Prec: 0.595, Rec: 0.448, F1: 0.479, Acc: 0.749\n",
      "Epoch: 32/50\n",
      "Epoch 1/1\n",
      "132/132 [==============================] - 31s 234ms/step - loss: 0.0719 - acc: 0.9761\n",
      "Test-Data: Prec: 0.551, Rec: 0.450, F1: 0.482, Acc: 0.740\n",
      "Epoch: 33/50\n",
      "Epoch 1/1\n",
      " 94/132 [====================>.........] - ETA: 8s - loss: 0.0584 - acc: 0.9787"
     ]
    }
   ],
   "source": [
    "for i in range(len(strings)):\n",
    "    string = strings[i]\n",
    "    print(\"approach: %s\" %(string))\n",
    "\n",
    "\n",
    "    generator = sequential_generator\n",
    "    train_sentences = train_sentences\n",
    "    devLabels = dev_labels\n",
    "    number_of_tests = 5\n",
    "    number_of_epochs = 50\n",
    "    labels2Id = labels2Idx\n",
    "    millionpostcorpus_tl_log = '/home/jindal/notebooks/jindal/NER/language_model/results_tl_millionpostcorpus_t2_' +string+'.txt' \n",
    "    print(\"log file: %s\" %(millionpostcorpus_tl_log))\n",
    "\n",
    "    millionpostcorpus_tl_save_weigths='/home/jindal/notebooks/jindal/NER/language_model/classification_model_tl_millionpostcorpus_t2_'+string+'.h5'\n",
    "    print(\"save weights file: %s\" %(millionpostcorpus_tl_save_weigths))\n",
    "    batch_size=32\n",
    "    millionpostcorpus_tl_train_file='/home/gwiedemann/notebooks/OffLang/sample_train.txt'\n",
    "    f1_measure='macro'\n",
    "    pos_label=1\n",
    "    strategy = unfreeze_strategy[i]\n",
    "    print(strategy)\n",
    "    load_model_weights=True\n",
    "    model_weights_file = '/home/jindal/notebooks/jindal/NER/language_model/model_pretrained_millionpostcorpus.h5'\n",
    "    nb_sequence_length = nb_sequence_length\n",
    "    nb_embedding_dims= nb_embedding_dims\n",
    "    check_for_generator=3\n",
    "\n",
    "    test_model_tl_unfreezing(generator=generator, \n",
    "               train_sentences=train_sentences, \n",
    "               devLabels=devLabels, \n",
    "               number_of_tests= number_of_tests,\n",
    "               number_of_epochs=number_of_epochs, \n",
    "               filename_to_log=millionpostcorpus_tl_log, \n",
    "               labels2Idx = labels2Id,\n",
    "               filename_to_save_weigths=millionpostcorpus_tl_save_weigths,\n",
    "               batch_size=batch_size,\n",
    "               unfreezing_strategy = strategy,       \n",
    "               train_file=millionpostcorpus_tl_train_file, \n",
    "               f1_measure=f1_measure, \n",
    "               pos_label=pos_label, \n",
    "               load_model_weights=load_model_weights,\n",
    "               model_weights_file = model_weights_file, \n",
    "               nb_sequence_length=nb_sequence_length, \n",
    "               nb_embedding_dims=nb_embedding_dims, \n",
    "               check_for_generator= check_for_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
