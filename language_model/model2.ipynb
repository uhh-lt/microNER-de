{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "import math\n",
    "import linecache\n",
    "import numpy as np \n",
    "from numpy import random\n",
    "from random import sample\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import *\n",
    "from keras import *\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform\n",
    "import re\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "# from attention_utils import get_activations, get_data_recurrent\n",
    "# from attention_decoder import AttentionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = fastText.load_model(\"/home/jindal/notebooks/fastText/wiki.de.bin\")\n",
    "\n",
    "nb_embedding_dims = ft.get_dimension()\n",
    "nb_embedding2_dims = nb_embedding_dims\n",
    "nb_sequence_length = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_tokenizer(textline):\n",
    "    textline = re.sub('@[\\w_]+', 'USER_MENTION', textline)\n",
    "    textline = re.sub('\\|LBR\\|', '', textline)\n",
    "    textline = re.sub('\\.\\.\\.+', '...', textline)\n",
    "    textline = re.sub('!!+', '!!', textline)\n",
    "    textline = re.sub('\\?\\?+', '??', textline)\n",
    "    words = re.compile('[\\U00010000-\\U0010ffff]|[\\w-]+|[^ \\w\\U00010000-\\U0010ffff]+', re.UNICODE).findall(textline.strip())\n",
    "    words = [w.strip() for w in words if w.strip() != '']\n",
    "    # print(words)\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_generator(filename, batch_size):\n",
    "    \n",
    "    file_length = sum(1 for line in open(filename, encoding = 'UTF-8'))\n",
    "    shuffled_indexes = range(1, file_length + 1)\n",
    "    # shuffled_indexes = sample(shuffled_indexes, len(shuffled_indexes))\n",
    "    index_position = 0\n",
    "    \n",
    "    batch_features_ft = np.zeros((batch_size, nb_sequence_length, nb_embedding_dims))\n",
    "    batch_features_lg = np.zeros((batch_size, nb_sequence_length, nb_embedding_dims))\n",
    "    # batch_features_idx = np.zeros((batch_size, nb_sequence_length))\n",
    "    batch_labels = np.zeros((batch_size, 2))\n",
    "\n",
    "    while True:\n",
    "        # print(len(features))\n",
    "        for i in range(batch_size):\n",
    "            line = linecache.getline(filename, shuffled_indexes[index_position])\n",
    "            data = line.strip().split('\\t')\n",
    "            batch_features_ft[i], batch_features_lg[i] = process_features(data[0], nb_sequence_length, nb_embedding_dims)\n",
    "            # print(batch_features_ft[i])\n",
    "            # print(batch_features_ft[i].shape)\n",
    "            batch_labels[i] = to_categorical(0 if data[1] == 'OTHER' else 1, n_labels)\n",
    "            index_position += 1\n",
    "            if index_position == file_length:\n",
    "                # shuffle indexes again\n",
    "                shuffled_indexes = range(1, file_length + 1)\n",
    "                # shuffled_indexes = sample(shuffled_indexes, len(shuffled_indexes))\n",
    "                index_position = 0\n",
    "                break\n",
    "        # yield [batch_features_ft, batch_features_lg], batch_labels\n",
    "        yield [batch_features_ft], batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_splitter = re.compile(\"[\\w+]|[\\W+]\", re.UNICODE)\n",
    "word_vectors_ft = {}\n",
    "def process_features(textline, nb_sequence_length, nb_embedding_dims):\n",
    "    words = twitter_tokenizer(textline)\n",
    "    # print(words)\n",
    "    features_ft = np.zeros((nb_sequence_length, nb_embedding_dims))\n",
    "    features_lg = np.zeros((nb_sequence_length, nb_embedding2_dims))\n",
    "    features_idx = np.zeros(nb_sequence_length)\n",
    "    max_words = min(len(words), nb_sequence_length)\n",
    "    idx = nb_sequence_length - len(words[:max_words])\n",
    "    for w in words[:max_words]:\n",
    "        if w in word_vectors_ft:\n",
    "            wv = word_vectors_ft[w]\n",
    "        else:\n",
    "            wv = ft.get_word_vector(w.lower())\n",
    "            word_vectors_ft[w] = wv\n",
    "        features_ft[idx] = wv\n",
    "        \n",
    "        if w in word2Idx:\n",
    "            wv = wordEmbeddings[word2Idx[w]]\n",
    "            widx = word2Idx[w]\n",
    "        else:\n",
    "            wv = wordEmbeddings[word2Idx[\"UNKNOWN_TOKEN\"]]\n",
    "            widx = word2Idx[\"UNKNOWN_TOKEN\"]\n",
    "        features_lg[idx] = wv\n",
    "        features_idx = widx\n",
    "        \n",
    "        idx = idx + 1\n",
    "    return features_ft, features_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lines = [line.strip().split(\"\\t\") for line in open('/home/gwiedemann/notebooks/OffLang/sample_train.txt', encoding = \"UTF-8\")]\n",
    "dev_lines = [line.strip().split(\"\\t\") for line in open('/home/gwiedemann/notebooks/OffLang/sample_dev.txt', encoding = \"UTF-8\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [x[0] for x in train_lines]\n",
    "train_labels = to_categorical([0 if x[1] == \"OTHER\" else 1 for x in train_lines])\n",
    "# train_labels = [0 if x[1] == \"OTHER\" else 1 for x in train_lines]\n",
    "\n",
    "dev_sentences = [x[0] for x in dev_lines]\n",
    "dev_labels = to_categorical([0 if x[1] == \"OTHER\" else 1 for x in dev_lines])\n",
    "# dev_labels = [0 if x[1] == \"OTHER\" else 1 for x in dev_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters={}\n",
    "for line in train_sentences:\n",
    "    for char in line:\n",
    "        characters[char] = True\n",
    "for line in dev_sentences:\n",
    "    for char in line:\n",
    "        characters[char] = True\n",
    "char2Idx={}\n",
    "for char in characters:\n",
    "    char2Idx[char] = len(char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "True\n",
      "[ 0.048675  0.13134  -0.103707 -0.178012 -0.095551 -0.171765 -0.482186\n",
      " -0.595483  0.40201  -0.0764    0.030391  0.053942  0.125109 -0.100393\n",
      " -0.18863  -0.040022  0.124366  0.234751  0.170881 -0.14696  -0.096499\n",
      "  0.076724  0.363462  0.15184   0.028145  0.108519 -0.384469  0.513485\n",
      " -0.080346  0.287282  0.129523 -0.205344 -0.189282  0.00303  -0.314163\n",
      " -0.253001 -0.191423 -0.3048    0.264441  0.04405  -0.715606  0.303819\n",
      "  0.421922  0.370784  0.012607  0.262544 -0.100403  0.354938  0.012659\n",
      " -0.312128  0.202812  0.053679  0.115874  0.039126  0.058098  0.092229\n",
      "  0.309017 -0.191012  0.020758 -0.226308 -0.363673  0.093612 -0.099952\n",
      "  0.361019 -0.094479 -0.422336 -0.18642  -0.236536 -0.519167  0.159582\n",
      "  0.338029 -0.18979   0.180626  0.125307 -0.662534  0.035188  0.484701\n",
      " -0.335092 -0.1776   -0.227792  0.038483 -0.3802   -0.534377 -0.782993\n",
      " -0.089097 -0.205562 -0.044407 -0.051924 -0.575704  0.018059 -0.053812\n",
      "  0.283002  0.514965 -0.486068  0.055361 -0.054333 -0.020527 -0.447207\n",
      " -0.16172  -0.323516 -0.140941  0.359253 -0.026572  0.03811  -0.262805\n",
      " -0.110643  0.071799 -0.294002  0.22942  -0.205949 -0.382046  0.401108\n",
      " -0.276722  0.214104 -0.595008  0.192986  0.455628 -0.350839 -0.045692\n",
      "  0.133086 -0.424625 -0.277588  0.024055  0.147867 -0.08691   0.571668\n",
      "  0.143583 -0.81787   0.066866  0.13196  -0.527486 -0.361454 -0.07502\n",
      " -0.335236 -0.333107  0.164847  0.156269  0.441192 -0.607866 -0.255168\n",
      "  0.330981 -0.084682  0.230935  0.307055  0.038844 -0.291582 -0.056673\n",
      "  0.462222  0.803219  0.228475 -0.201439  0.219928  0.383817  0.557068\n",
      " -0.036326 -0.242435  0.233065 -0.228331 -0.508134  0.291427 -0.519309\n",
      "  0.044088 -0.086498  0.302048  0.390556  0.271205  0.217828 -0.050916\n",
      "  0.080193 -0.043897 -0.282846 -0.112332  0.625581  0.106275  0.279431\n",
      " -0.057829 -0.098599 -0.407969 -0.477591 -0.219932  0.086368  0.131618\n",
      "  0.551522  0.111237 -0.223282  0.187202  0.068917 -0.052917  0.161887\n",
      " -0.154098 -0.164078 -0.538337  0.1796   -0.556684  0.071236 -0.328513\n",
      " -0.136216  0.262133  0.002567  0.417626 -0.21965   0.341746  0.227955\n",
      " -0.435188  0.501005 -0.03706  -0.059332  0.129726 -0.312358  0.609214\n",
      "  0.199549  0.015094  0.408183 -0.116013 -0.056285 -0.167054  0.248529\n",
      " -0.056687  0.150728 -0.297201  0.064892 -0.190823  0.408725 -0.109309\n",
      "  0.08771   0.501691  0.220294  0.574126 -0.391221 -0.062028 -0.198907\n",
      " -0.347254 -0.454964 -0.522999 -0.624555 -0.286765 -0.50417  -0.076217\n",
      " -0.326018  0.204136 -0.680892 -0.376736  0.158066 -0.312117  0.264556\n",
      "  0.146177 -0.308771 -0.008688 -0.314001  0.125771 -0.201756 -0.659012\n",
      " -0.622982 -0.040028 -0.485648 -0.177484 -0.464318  0.244852 -0.274885\n",
      " -0.251469 -0.039978 -0.176292  0.329761 -0.472007 -0.102019  0.262121\n",
      "  0.111076 -0.240045 -0.117089 -0.076003  0.616422 -0.408125  0.176903\n",
      "  0.313987 -0.799575 -0.03966   0.252346 -0.7993   -0.436084  0.070221\n",
      "  0.290749 -0.243656 -0.126341 -0.3677    0.14742  -0.125789 -0.181893\n",
      " -0.072211  0.596252 -0.484738  0.453664  0.428786  0.458826  0.23167\n",
      "  0.266693 -0.253493 -0.560137  0.243464  0.339786 -0.142555]\n",
      "True\n",
      "[ 1.337370e-01  3.119880e-01  2.753100e-02  8.878200e-02  6.563800e-01\n",
      "  3.171850e-01 -2.109500e-02  1.406300e-02  5.340040e-01  2.578490e-01\n",
      "  2.588490e-01 -1.048940e-01  3.620060e-01 -2.829930e-01 -1.473980e-01\n",
      "  4.159500e-02  2.373150e-01 -1.166190e-01 -3.209970e-01  1.039400e-01\n",
      " -1.977830e-01  3.936060e-01  4.686630e-01 -1.302900e-01  8.249750e-01\n",
      "  1.997430e-01 -1.715120e-01 -3.668870e-01 -3.890720e-01  5.100300e-02\n",
      "  3.331560e-01  2.992550e-01 -7.163090e-01  4.123360e-01  1.004790e-01\n",
      "  5.032110e-01  2.316500e-01 -3.905700e-01 -6.022000e-02 -1.865600e-02\n",
      " -1.614920e-01 -2.814600e-02 -2.197560e-01  3.904800e-01  2.563850e-01\n",
      "  3.242140e-01  4.594100e-02  2.230130e-01 -2.587380e-01  2.362860e-01\n",
      " -1.809200e-01 -3.878300e-01 -2.002290e-01 -8.909200e-02 -3.415590e-01\n",
      "  2.324870e-01  5.306480e-01 -6.425640e-01  1.317730e-01 -8.793100e-02\n",
      " -1.154690e-01 -2.851320e-01 -6.405800e-02  3.653600e-02 -6.911800e-01\n",
      " -3.942210e-01 -2.342440e-01  5.719840e-01  3.857710e-01 -2.230240e-01\n",
      " -1.377610e-01  4.562030e-01 -8.640000e-04 -2.019700e-01  1.394330e-01\n",
      " -3.189680e-01  2.269320e-01 -8.128900e-01 -1.665450e-01 -2.106860e-01\n",
      " -1.233730e-01 -2.005240e-01 -2.490880e-01 -9.616000e-03  1.376610e-01\n",
      " -3.871670e-01  1.415940e-01 -2.581360e-01 -6.848100e-02 -3.853580e-01\n",
      " -1.739150e-01 -1.205950e-01  3.701800e-02  1.290470e-01  2.718080e-01\n",
      "  1.397000e-03  4.746900e-02 -4.013470e-01  3.374180e-01  1.740330e-01\n",
      " -9.604900e-02  2.309360e-01  1.584430e-01 -1.451420e-01 -7.373700e-01\n",
      " -2.980550e-01  4.691900e-02 -5.936800e-02 -7.401200e-02 -1.220700e-02\n",
      " -6.021500e-01  5.031280e-01  4.563200e-02  2.789290e-01  2.054010e-01\n",
      " -2.391390e-01  4.018770e-01 -2.124840e-01 -4.382370e-01  8.838800e-02\n",
      "  3.819460e-01 -1.218980e-01  1.525900e-02  1.181510e-01 -3.644050e-01\n",
      " -2.683930e-01  6.898590e-01  4.830960e-01  2.731460e-01 -3.676000e-02\n",
      "  3.744300e-02  1.881210e-01  1.214724e+00  3.098700e-01  4.820860e-01\n",
      "  2.049310e-01  4.061040e-01  3.263600e-02 -4.891120e-01 -1.428150e-01\n",
      " -1.036670e-01 -2.730000e-01  8.109000e-02  1.650080e-01  4.265980e-01\n",
      " -1.844760e-01  4.881900e-02  1.883490e-01 -2.180640e-01  8.600010e-01\n",
      " -4.362220e-01  2.241100e-01 -2.195190e-01 -2.854310e-01  2.651080e-01\n",
      "  1.153370e-01 -6.132930e-01 -7.199500e-02  5.914700e-01  6.580810e-01\n",
      " -5.669110e-01  2.940930e-01  2.032530e-01 -9.924000e-03  3.152460e-01\n",
      " -4.149700e-01  4.272700e-02  1.453460e-01  2.757900e-01 -4.792810e-01\n",
      "  3.255270e-01 -3.275100e-02  4.276470e-01  1.296000e-03  9.812100e-02\n",
      "  4.664120e-01  4.249010e-01  6.795100e-01  3.243850e-01 -4.404320e-01\n",
      " -1.189840e-01  2.402580e-01 -5.652590e-01 -3.029400e-02 -2.205800e-01\n",
      "  2.131790e-01  5.143540e-01  1.872420e-01  2.343530e-01 -3.751430e-01\n",
      " -2.849710e-01  3.117460e-01 -2.105000e-03 -1.132240e-01 -4.513940e-01\n",
      "  2.399700e-01 -1.421890e-01  2.725730e-01  1.422000e-01  1.363000e-02\n",
      "  4.398800e-02 -5.415600e-02 -1.313570e-01 -6.133570e-01 -1.785390e-01\n",
      "  6.290530e-01 -3.088300e-02  1.957740e-01  5.562300e-02  5.831850e-01\n",
      " -9.027030e-01 -3.035830e-01 -2.643080e-01 -4.708150e-01 -1.036840e-01\n",
      "  8.604600e-02  1.915070e-01 -2.692180e-01  1.933100e-02 -1.229520e-01\n",
      "  4.319240e-01  5.776540e-01  1.799040e-01  2.684260e-01  2.102300e-02\n",
      "  3.026290e-01  1.055590e-01 -1.077600e-02 -1.911940e-01 -1.600120e-01\n",
      " -4.174390e-01  1.407020e-01 -4.629640e-01 -4.655920e-01 -1.786300e-02\n",
      " -5.892000e-03  1.439410e-01 -3.018000e-02 -4.274200e-01 -1.857600e-01\n",
      " -3.894300e-02  9.635600e-02  6.124000e-02  3.222340e-01 -1.011910e-01\n",
      "  8.335900e-01 -6.326000e-02 -3.348280e-01  2.663600e-01  1.604560e-01\n",
      " -1.681100e-02  7.737500e-01 -4.278070e-01 -6.816000e-03 -2.256400e-02\n",
      " -5.204990e-01  6.070600e-02  8.373060e-01 -7.067040e-01 -5.166860e-01\n",
      "  4.699710e-01  3.903760e-01 -5.749100e-02  2.760740e-01  8.649600e-02\n",
      "  5.949100e-02  2.169430e-01  7.321000e-03 -2.446620e-01 -2.866190e-01\n",
      "  2.862190e-01  1.457470e-01 -2.498320e-01 -1.953710e-01 -7.142650e-01\n",
      "  1.539660e-01  4.816600e-01 -6.295660e-01 -1.410540e-01  2.501710e-01\n",
      "  6.197390e-01  3.949930e-01  4.248100e-01 -3.513890e-01 -3.961120e-01\n",
      " -5.034130e-01 -4.600710e-01  4.257330e-01  3.248450e-01  2.037660e-01\n",
      "  1.645760e-01  4.575000e-02  1.421850e-01 -2.028220e-01  1.563550e-01\n",
      " -3.559900e-02  6.589800e-02  4.639840e-01  1.352500e-02 -5.877830e-01]\n"
     ]
    }
   ],
   "source": [
    "nb_embedding2_dims = wordEmbeddings[1].shape[0]\n",
    "# print(nb_embedding2_dims)\n",
    "# print('für' in word2Idx)\n",
    "# print(wordEmbeddings[word2Idx['für']])\n",
    "# print('Ute' in word2Idx)\n",
    "# print(wordEmbeddings[word2Idx['Ute']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 75, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 75, 200)      320800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 75, 200)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 73, 200)      120200      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 72, 200)      160200      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 71, 200)      200200      leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 73, 200)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 72, 200)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 71, 200)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 200)          0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 200)          0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 200)          0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          60100       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            202         leaky_re_lu_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 861,702\n",
      "Trainable params: 861,702\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input_embedding = Input(shape = (nb_sequence_length, nb_embedding_dims))\n",
    "lstm_block = Bidirectional(LSTM(100, dropout = 0.5, return_sequences=True))(model_input_embedding)\n",
    "lstm_block = LeakyReLU()(lstm_block)\n",
    "\n",
    "filter_sizes = (3, 4, 5)\n",
    "conv_blocks = []\n",
    "for sz in filter_sizes:\n",
    "    conv = Conv1D(\n",
    "        filters = 200,\n",
    "        kernel_size = sz,\n",
    "        padding = 'valid',\n",
    "        strides = 1\n",
    "    )(lstm_block)\n",
    "    conv = LeakyReLU()(conv)\n",
    "    conv = GlobalMaxPooling1D()(conv)\n",
    "    conv = Dropout(0.5)(conv)\n",
    "    conv_blocks.append(conv)\n",
    "model_concatenated = concatenate([conv_blocks[0], conv_blocks[1], conv_blocks[2]])\n",
    "# model_concatenated = Dropout(0.8)(model_concatenated)\n",
    "model_concatenated = Dense(100)(model_concatenated)\n",
    "model_concatenated = LeakyReLU()(model_concatenated)\n",
    "model_output = Dense(n_labels, activation = \"softmax\")(model_concatenated)\n",
    "model = Model(model_input_embedding, model_output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_per_epoch = len(train_sentences)\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "steps_per_epoch = math.ceil(samples_per_epoch / batch_size)\n",
    "checkpoint = ModelCheckpoint('best_classification_model.h5', \n",
    "                             monitor='val_acc', \n",
    "                             verbose = 1, \n",
    "                             save_best_only = True, \n",
    "                             save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'word2Idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5cd3f9c64a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequential_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/gwiedemann/notebooks/OffLang/sample_dev.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_sentences\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdev_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/NER2/lib/python3.5/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    656\u001b[0m                             \u001b[0;31m# => Serialize calls to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                             \u001b[0;31m# infinite iterator/generator's next() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                             \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-f205812b0cfb>\u001b[0m in \u001b[0;36msequential_generator\u001b[0;34m(filename, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinecache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_position\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mbatch_features_ft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_features_lg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_embedding_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# print(batch_features_ft[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# print(batch_features_ft[i].shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a34bde1f5c03>\u001b[0m in \u001b[0;36mprocess_features\u001b[0;34m(textline, nb_sequence_length, nb_embedding_dims)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mfeatures_ft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2Idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordEmbeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2Idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mwidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2Idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2Idx' is not defined"
     ]
    }
   ],
   "source": [
    "dev_batch_size = len(dev_sentences)\n",
    "model.fit_generator(\n",
    "    sequential_generator('/home/gwiedemann/notebooks/OffLang/sample_train.txt', batch_size), \n",
    "    steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
    "    validation_data = sequential_generator('/home/gwiedemann/notebooks/OffLang/sample_dev.txt', dev_batch_size),\n",
    "    validation_steps = math.ceil(len(dev_sentences) / dev_batch_size),\n",
    "    callbacks = [checkpoint]\n",
    ")\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_classification_model.h5')\n",
    "model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics = ['accuracy'])\n",
    "testset_features_e1 = np.zeros((len(dev_sentences), nb_sequence_length, nb_embedding_dims))\n",
    "testset_features_e2 = np.zeros((len(dev_sentences), nb_sequence_length, nb_embedding2_dims))   \n",
    "for i in range(len(dev_sentences)):\n",
    "    testset_features_e1[i], testset_features_e2[i] = process_features(dev_sentences[i], nb_sequence_length, nb_embedding_dims)\n",
    "results = model.predict(testset_features_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Data: Prec: 0.738, Rec: 0.685, F1: 0.711, Acc: 0.816\n"
     ]
    }
   ],
   "source": [
    "idx2Label = {0 : \"OTHER\", 1 : \"OFFENSIVE\"}\n",
    "predLabels = results.argmax(axis=-1)\n",
    "devLabels = [0 if x[1] == \"OTHER\" else 1 for x in dev_lines]\n",
    "# print(idx2Label)\n",
    "# print(predLabels)\n",
    "# print(devLabels)\n",
    "f1 = f1_score(devLabels, predLabels, average='binary', pos_label=1)\n",
    "r = recall_score(devLabels, predLabels, average='binary', pos_label=1)\n",
    "p = precision_score(devLabels, predLabels, average='binary', pos_label=1)\n",
    "a = accuracy_score(devLabels, predLabels)\n",
    "print(\"Test-Data: Prec: %.3f, Rec: %.3f, F1: %.3f, Acc: %.3f\" % (p, r, f1, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
