{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'jindal/NER-Bi-LSTM-CNN')\n",
    "\n",
    "\n",
    "import numpy as np \n",
    "from validation import compute_f1\n",
    "from keras.models import Model\n",
    "from keras.layers import TimeDistributed,Conv1D,Dense,Embedding,Input,Dropout,LSTM,Bidirectional,MaxPooling1D,Flatten,concatenate\n",
    "from prepro import readfile,createBatches,createMatrices,iterate_minibatches,addCharInformatioin,padding\n",
    "from keras.utils import plot_model,Progbar\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.initializers import RandomUniform\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "import sklearn\n",
    "import subprocess\n",
    "\n",
    "epochs = 70\n",
    "trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tag_dataset(dataset):\n",
    "    correctLabels = []\n",
    "    predLabels = []\n",
    "    b = Progbar(len(dataset))\n",
    "    for i,data in enumerate(dataset):    \n",
    "        tokens, casing,char, labels = data\n",
    "        tokens = np.asarray([tokens])     \n",
    "        casing = np.asarray([casing])\n",
    "        char = np.asarray([char])\n",
    "        pred = model.predict([tokens, casing,char], verbose=False)[0]   \n",
    "        pred = pred.argmax(axis=-1) #Predict the classes            \n",
    "        correctLabels.append(labels)\n",
    "        predLabels.append(pred)\n",
    "        b.update(i)\n",
    "    return predLabels, correctLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# changing all deriv and part to misc. with BIO\n",
    "def modify_labels(dataset):\n",
    "    bad_labels = ['I-PERderiv','I-OTHpart','B-ORGderiv', 'I-OTH','B-OTHpart','B-LOCderiv','I-LOCderiv','I-OTHderiv','B-PERderiv','B-OTHderiv','B-PERpart','I-PERpart','I-LOCpart','B-LOCpart','I-ORGpart','I-ORGderiv','B-ORGpart','B-OTH']\n",
    "    for sentence in dataset:\n",
    "        for word in sentence:\n",
    "            label = word[1]\n",
    "            if label in bad_labels:\n",
    "                first_char = label[0]\n",
    "                if first_char == 'B' :\n",
    "                    word[1] = 'B-MISC'\n",
    "                else:\n",
    "                    word[1] = 'I-MISC'\n",
    "    return dataset\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# preproecessing data from GermEval\n",
    "def get_sentences(path):\n",
    "    sentences=[]\n",
    "    with open(path,'rb') as f:\n",
    "    #     lines = f.readlines()\n",
    "        sentence=[]\n",
    "        for line in f:\n",
    "            try:\n",
    "                splits = [x.decode() for x in line.split()]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            try:\n",
    "                if splits[0]!='#':\n",
    "                    temp = [splits[1],splits[2]]\n",
    "                    sentence.append(temp)\n",
    "                else:\n",
    "                    if len(sentence):\n",
    "                        sentences.append(sentence)\n",
    "                    sentence=[]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    return sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preproecessing data from Conll\n",
    "def get_sentences(filename):\n",
    "    '''\n",
    "        -DOCSTART- -X- -X- O\n",
    "\n",
    "    EU NNP B-NP B-ORG\n",
    "    rejects VBZ B-VP O\n",
    "    German JJ B-NP B-MISC\n",
    "    call NN I-NP O\n",
    "    to TO B-VP O\n",
    "    boycott VB I-VP O\n",
    "    British JJ B-NP B-MISC\n",
    "    lamb NN I-NP O\n",
    "    . . O O\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    read file\n",
    "    return format :\n",
    "    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n",
    "    '''\n",
    "    f = open(filename,'rb')\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in f:\n",
    "        splits = line.split()\n",
    "        try:\n",
    "            word=splits[0].decode()\n",
    "            if word=='-DOCSTART-':\n",
    "                continue\n",
    "            label=splits[-1].decode()\n",
    "            temp=[word,label]\n",
    "            sentence.append(temp)\n",
    "        except Exception as e:\n",
    "            if len(sentence)!=0:\n",
    "                sentences.append(sentence)\n",
    "                sentence=[]\n",
    "    return sentences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12152\n",
      "2867\n",
      "3005\n"
     ]
    }
   ],
   "source": [
    "train_sentences = get_sentences('/home/jindal/notebooks/Resources/CONLL/deu/deu_utf.train')\n",
    "dev_sentences = get_sentences('/home/jindal/notebooks/Resources/CONLL/deu/deu_utf.testa')\n",
    "test_sentences = get_sentences('/home/jindal/notebooks/Resources/CONLL/deu/deu_utf.testb')\n",
    "\n",
    "print(len(train_sentences))\n",
    "print(len(dev_sentences))\n",
    "print(len(test_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', 'O'], ['und', 'O'], ['Erz√§hlung', 'O'], ['oder', 'O'], [':', 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(train_sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train_sentences = modify_labels(train_sentences)\n",
    "# dev_sentences = modify_labels(dev_sentences)\n",
    "# test_sentences = modify_labels(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainSentences = addCharInformatioin(train_sentences)\n",
    "devSentences = addCharInformatioin(dev_sentences)\n",
    "testSentences = addCharInformatioin(test_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "labelSet = set()\n",
    "words = {}\n",
    "characters=set()\n",
    "\n",
    "for dataset in [trainSentences, devSentences, testSentences]:\n",
    "    for sentence in dataset:\n",
    "        for token,char,label in sentence:\n",
    "            for c in char:\n",
    "                characters.add(c)\n",
    "            labelSet.add(label)\n",
    "            words[token.lower()] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O', 'I-ORG', 'B-LOC', 'B-ORG', 'B-PER', 'B-MISC', 'I-LOC', 'I-MISC', 'I-PER'}\n"
     ]
    }
   ],
   "source": [
    "print(labelSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# :: Create a mapping for the labels ::\n",
    "label2Idx = {}\n",
    "for label in labelSet:\n",
    "    label2Idx[label] = len(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-PER': 4, 'I-ORG': 1, 'I-LOC': 6, 'B-LOC': 2, 'B-ORG': 3, 'I-MISC': 7, 'I-PER': 8, 'B-MISC': 5}\n"
     ]
    }
   ],
   "source": [
    "print(label2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# :: Hard coded case lookup ::\n",
    "case2Idx = {'numeric': 0, 'allLower':1, 'allUpper':2, 'initialUpper':3, 'other':4, 'mainly_numeric':5, 'contains_digit': 6, 'PADDING_TOKEN':7}\n",
    "caseEmbeddings = np.identity(len(case2Idx), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "string_words = ' '.join(words.keys())\n",
    "# print(string_words)\n",
    "f = open('/home/jindal/notebooks/jindal/NER/german_words_conll.txt','wb')\n",
    "f.write(string_words.encode())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "{'allLower': 1, 'numeric': 0, 'contains_digit': 6, 'initialUpper': 3, 'mainly_numeric': 5, 'allUpper': 2, 'other': 4, 'PADDING_TOKEN': 7}\n"
     ]
    }
   ],
   "source": [
    "print(caseEmbeddings)\n",
    "print(case2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word2Idx={}\n",
    "wordEmbeddings=[]\n",
    "\n",
    "# created a file by the name of german_words.txt in /fastText. Containing all the words in our dataset\n",
    "with open('german_word_embeddings_conll.txt','rb') as f:\n",
    "    for line in f:\n",
    "        splits = line.split()\n",
    "        word = splits[0].decode()\n",
    "#         print(word.decode())\n",
    "        if len(word2Idx) == 0: #Add padding+unknown\n",
    "            word2Idx[\"PADDING_TOKEN\"] = len(word2Idx)\n",
    "            vector = np.zeros(len(splits)-1) #Zero vector vor 'PADDING' word\n",
    "            wordEmbeddings.append(vector)\n",
    "\n",
    "            word2Idx[\"UNKNOWN_TOKEN\"] = len(word2Idx)\n",
    "            vector = np.random.uniform(-0.25, 0.25, len(splits)-1)\n",
    "            wordEmbeddings.append(vector)\n",
    "            \n",
    "        word2Idx[word]=len(word2Idx)\n",
    "        embedding = np.array([float(num) for num in splits[1:]])\n",
    "        wordEmbeddings.append(embedding)\n",
    "wordEmbeddings=np.array(wordEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "# print(wordEmbeddings[2])\n",
    "print(len(wordEmbeddings[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'\": 0, 'J': 1, 'o': 48, '3': 47, '%': 28, 's': 2, 'P': 5, '√±': 91, 'F': 51, '√ú': 3, 'V': 52, '/': 4, 'U': 49, '√©': 53, '5': 54, '√ß': 6, 'l': 7, '1': 56, ')': 57, '√º': 58, 'I': 8, 'D': 59, '*': 9, '&': 10, '\"': 33, '√ñ': 11, 'C': 61, '.': 86, 'K': 50, 'H': 12, '2': 63, '¬ß': 64, '√®': 13, 't': 14, 'z': 65, '√¥': 15, 'v': 16, '√≤': 55, ';': 17, '=': 66, 'N': 67, 'G': 18, 'M': 68, 'T': 69, 'E': 70, 'h': 71, 'j': 72, '√ü': 19, 'c': 73, '9': 74, 'X': 20, '√™': 21, 'Z': 75, 'q': 22, '√°': 23, 'y': 24, '√∂': 26, 'w': 77, '√≠': 78, '4': 27, '0': 79, ',': 80, '8': 81, '√≥': 29, ':': 30, 'm': 31, 'L': 32, 'R': 34, 'i': 93, '-': 35, 'a': 82, '(': 83, '√Ñ': 84, 'e': 36, '6': 37, 'd': 85, '√§': 38, 'g': 60, 'n': 39, 'S': 87, '?': 40, '!': 89, 'B': 90, 'x': 62, 'Q': 41, 'f': 92, 'r': 42, 'O': 43, 'p': 44, 'Y': 25, 'W': 45, 'k': 94, 'u': 46, '+': 95, '√¨': 96, 'A': 97, 'b': 88, '7': 76}\n"
     ]
    }
   ],
   "source": [
    "char2Idx={}\n",
    "for char in characters:\n",
    "    char2Idx[char] = len(char2Idx)\n",
    "print(char2Idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ereignis', ['E', 'r', 'e', 'i', 'g', 'n', 'i', 's'], 'O'], ['und', ['u', 'n', 'd'], 'O'], ['Erz√§hlung', ['E', 'r', 'z', '√§', 'h', 'l', 'u', 'n', 'g'], 'O'], ['oder', ['o', 'd', 'e', 'r'], 'O'], [':', [':'], 'O']]\n"
     ]
    }
   ],
   "source": [
    "print(trainSentences[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# createMatrices: for every sentence, changes its words, cases,characters, labels to its corresponding id in their embeddings\n",
    "# padding is used to pad the character indices to a fixed size=52\n",
    "train_set = padding(createMatrices(trainSentences,word2Idx,  label2Idx, case2Idx,char2Idx))\n",
    "dev_set = padding(createMatrices(devSentences,word2Idx, label2Idx, case2Idx,char2Idx))\n",
    "test_set = padding(createMatrices(testSentences, word2Idx, label2Idx, case2Idx,char2Idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10296, 38277, 17527, 29285, 40756], [3, 1, 3, 1, 4], array([[70, 42, 36, 93, 60, 39, 93,  2,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0],\n",
      "       [46, 39, 85,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0],\n",
      "       [70, 42, 65, 38, 71,  7, 46, 39, 60,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0],\n",
      "       [48, 85, 36, 42,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0],\n",
      "       [30,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0]], dtype=int32), [0, 0, 0, 0, 0]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# train-set[][0]: corresponds to the ids of the words in the sentence\n",
    "# train_set[][1]: corresponds to the ids of the cases of the words\n",
    "# train_set[][2]: contains numpy arrays, one corresponding to every word, each containing the indices of the characters of that word\n",
    "# the numpy arrays have a fixed size (padding or truncation) to 52\n",
    "# train_set[][3]: corresponds to the ids of the labels of every word\n",
    "\n",
    "print(train_set[0])\n",
    "print(len(train_set[0][0])) # gives the number of words in the sentence\n",
    "# print((train_set[0][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "idx2Label = {v: k for k, v in label2Idx.items()}\n",
    "\n",
    "train_batch,train_batch_len = createBatches(train_set)\n",
    "dev_batch,dev_batch_len = createBatches(dev_set)\n",
    "test_batch,test_batch_len = createBatches(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input (InputLayer)         (None, None, 52)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (TimeDistributed (None, None, 52, 30) 2940        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, None, 52, 30) 0           char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_16 (TimeDistri (None, None, 52, 30) 2730        dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "maxpool (TimeDistributed)       (None, None, 1, 30)  0           time_distributed_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "words_input (InputLayer)        (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "casing_input (InputLayer)       (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_17 (TimeDistri (None, None, 30)     0           maxpool[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_16 (Embedding)        (None, None, 300)    12806400    words_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_17 (Embedding)        (None, None, 8)      64          casing_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, None, 30)     0           time_distributed_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, None, 338)    0           embedding_16[0][0]               \n",
      "                                                                 embedding_17[0][0]               \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, None, 400)    862400      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_18 (TimeDistri (None, None, 9)      3609        bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "crf_6 (CRF)                     (None, None, 9)      189         time_distributed_18[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 13,678,332\n",
      "Trainable params: 871,868\n",
      "Non-trainable params: 12,806,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "words_input = Input(shape=(None,),dtype='int32',name='words_input')\n",
    "words = Embedding(input_dim=wordEmbeddings.shape[0], output_dim=wordEmbeddings.shape[1],  weights=[wordEmbeddings], trainable=False)(words_input)\n",
    "casing_input = Input(shape=(None,), dtype='int32', name='casing_input')\n",
    "casing = Embedding(output_dim=caseEmbeddings.shape[1], input_dim=caseEmbeddings.shape[0], weights=[caseEmbeddings], trainable=False)(casing_input)\n",
    "character_input=Input(shape=(None,52,),name='char_input')\n",
    "embed_char_out=TimeDistributed(Embedding(len(char2Idx),30,embeddings_initializer=RandomUniform(minval=-0.5, maxval=0.5)), name='char_embedding')(character_input)\n",
    "dropout= Dropout(0.5, name='dropout1')(embed_char_out)\n",
    "conv1d_out= TimeDistributed(Conv1D(kernel_size=3, filters=30, padding='same',activation='tanh', strides=1, name='conv'))(dropout)\n",
    "maxpool_out=TimeDistributed(MaxPooling1D(52), name='maxpool')(conv1d_out)\n",
    "char = TimeDistributed(Flatten())(maxpool_out)\n",
    "char = Dropout(0.5)(char)\n",
    "output = concatenate([words, casing,char])\n",
    "output = Bidirectional(LSTM(200, return_sequences=True, dropout=0.50, recurrent_dropout=0.25))(output)\n",
    "output = TimeDistributed(Dense(len(label2Idx)))(output)\n",
    "crf = CRF(len(label2Idx))\n",
    "output = crf(output)\n",
    "model = Model(inputs=[words_input, casing_input,character_input], outputs=[output])\n",
    "model.compile(loss=crf.loss_function, optimizer='nadam', metrics=[crf.accuracy])\n",
    "model.summary()\n",
    "# plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/70\n",
      "82/79 [===============================] - 20s 248ms/step\n",
      "88/79 [=================================] - 21s 235ms/step\n",
      "92/79 [==================================] - 21s 230ms/step\n",
      "94/79 [===================================] - 21s 229ms/step\n",
      "100/79 [=====================================] - 22s 219ms/step\n",
      "Epoch 1/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 14s 157ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "Epoch 2/70\n",
      "82/79 [===============================] - 14s 174ms/step\n",
      "88/79 [=================================] - 15s 166ms/step\n",
      "92/79 [==================================] - 15s 164ms/step\n",
      "94/79 [===================================] - 15s 164ms/step\n",
      "100/79 [=====================================] - 16s 159ms/step\n",
      "Epoch 3/70\n",
      "82/79 [===============================] - 13s 163ms/step\n",
      "88/79 [=================================] - 14s 156ms/step\n",
      "92/79 [==================================] - 14s 154ms/step\n",
      "94/79 [===================================] - 14s 154ms/step\n",
      "100/79 [=====================================] - 15s 150ms/step\n",
      "Epoch 4/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 159ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 5/70\n",
      "82/79 [===============================] - 13s 164ms/step\n",
      "88/79 [=================================] - 14s 157ms/step\n",
      "92/79 [==================================] - 14s 154ms/step\n",
      "94/79 [===================================] - 15s 155ms/step\n",
      "100/79 [=====================================] - 15s 150ms/step\n",
      "Epoch 6/70\n",
      "82/79 [===============================] - 13s 164ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 152ms/step\n",
      "Epoch 7/70\n",
      "82/79 [===============================] - 13s 164ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 155ms/step\n",
      "94/79 [===================================] - 15s 156ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 8/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 159ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 9/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 160ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 10/70\n",
      "82/79 [===============================] - 15s 178ms/step\n",
      "88/79 [=================================] - 15s 171ms/step\n",
      "92/79 [==================================] - 15s 168ms/step\n",
      "94/79 [===================================] - 16s 169ms/step\n",
      "100/79 [=====================================] - 16s 163ms/step\n",
      "Epoch 11/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 160ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 159ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "Epoch 12/70\n",
      "82/79 [===============================] - 14s 171ms/step\n",
      "88/79 [=================================] - 15s 165ms/step\n",
      "92/79 [==================================] - 15s 163ms/step\n",
      "94/79 [===================================] - 15s 164ms/step\n",
      "100/79 [=====================================] - 16s 159ms/step\n",
      "Epoch 13/70\n",
      "82/79 [===============================] - 15s 178ms/step\n",
      "88/79 [=================================] - 15s 170ms/step\n",
      "92/79 [==================================] - 15s 167ms/step\n",
      "94/79 [===================================] - 16s 168ms/step\n",
      "100/79 [=====================================] - 16s 162ms/step\n",
      "Epoch 14/70\n",
      "82/79 [===============================] - 15s 183ms/step\n",
      "88/79 [=================================] - 15s 176ms/step\n",
      "92/79 [==================================] - 16s 172ms/step\n",
      "94/79 [===================================] - 16s 173ms/step\n",
      "100/79 [=====================================] - 17s 168ms/step\n",
      "Epoch 15/70\n",
      "82/79 [===============================] - 14s 176ms/step\n",
      "88/79 [=================================] - 15s 168ms/step\n",
      "92/79 [==================================] - 15s 165ms/step\n",
      "94/79 [===================================] - 16s 166ms/step\n",
      "100/79 [=====================================] - 16s 161ms/step\n",
      "Epoch 16/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 159ms/step\n",
      "94/79 [===================================] - 15s 160ms/step\n",
      "100/79 [=====================================] - 15s 154ms/step\n",
      "Epoch 17/70\n",
      "82/79 [===============================] - 14s 174ms/step\n",
      "88/79 [=================================] - 15s 166ms/step\n",
      "92/79 [==================================] - 15s 163ms/step\n",
      "94/79 [===================================] - 15s 163ms/step\n",
      "100/79 [=====================================] - 16s 157ms/step\n",
      "Epoch 18/70\n",
      "82/79 [===============================] - 15s 178ms/step\n",
      "88/79 [=================================] - 15s 171ms/step\n",
      "92/79 [==================================] - 15s 167ms/step\n",
      "94/79 [===================================] - 16s 168ms/step\n",
      "100/79 [=====================================] - 16s 162ms/step\n",
      "Epoch 19/70\n",
      "82/79 [===============================] - 14s 176ms/step\n",
      "88/79 [=================================] - 15s 169ms/step\n",
      "92/79 [==================================] - 15s 166ms/step\n",
      "94/79 [===================================] - 16s 166ms/step\n",
      "100/79 [=====================================] - 16s 161ms/step\n",
      "Epoch 20/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 160ms/step\n",
      "92/79 [==================================] - 14s 157ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 152ms/step\n",
      "Epoch 21/70\n",
      "82/79 [===============================] - 14s 176ms/step\n",
      "88/79 [=================================] - 15s 168ms/step\n",
      "92/79 [==================================] - 15s 165ms/step\n",
      "94/79 [===================================] - 16s 165ms/step\n",
      "100/79 [=====================================] - 16s 159ms/step\n",
      "Epoch 22/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 14s 157ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 152ms/step\n",
      "Epoch 23/70\n",
      "82/79 [===============================] - 14s 166ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 155ms/step\n",
      "94/79 [===================================] - 15s 156ms/step\n",
      "100/79 [=====================================] - 15s 150ms/step\n",
      "Epoch 24/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "Epoch 25/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "Epoch 26/70\n",
      "82/79 [===============================] - 15s 177ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/79 [=================================] - 15s 170ms/step\n",
      "92/79 [==================================] - 15s 166ms/step\n",
      "94/79 [===================================] - 16s 167ms/step\n",
      "100/79 [=====================================] - 16s 161ms/step\n",
      "Epoch 27/70\n",
      "82/79 [===============================] - 13s 162ms/step\n",
      "88/79 [=================================] - 14s 155ms/step\n",
      "92/79 [==================================] - 14s 152ms/step\n",
      "94/79 [===================================] - 14s 153ms/step\n",
      "100/79 [=====================================] - 15s 147ms/step\n",
      "Epoch 28/70\n",
      "82/79 [===============================] - 14s 172ms/step\n",
      "88/79 [=================================] - 14s 164ms/step\n",
      "92/79 [==================================] - 15s 161ms/step\n",
      "94/79 [===================================] - 15s 162ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 29/70\n",
      "82/79 [===============================] - 14s 170ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 159ms/step\n",
      "94/79 [===================================] - 15s 160ms/step\n",
      "100/79 [=====================================] - 15s 155ms/step\n",
      "Epoch 30/70\n",
      "82/79 [===============================] - 14s 165ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 155ms/step\n",
      "94/79 [===================================] - 15s 155ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 31/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 159ms/step\n",
      "94/79 [===================================] - 15s 160ms/step\n",
      "100/79 [=====================================] - 15s 154ms/step\n",
      "Epoch 32/70\n",
      "82/79 [===============================] - 14s 170ms/step\n",
      "88/79 [=================================] - 14s 163ms/step\n",
      "92/79 [==================================] - 15s 161ms/step\n",
      "94/79 [===================================] - 15s 161ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 33/70\n",
      "82/79 [===============================] - 14s 174ms/step\n",
      "88/79 [=================================] - 15s 167ms/step\n",
      "92/79 [==================================] - 15s 164ms/step\n",
      "94/79 [===================================] - 15s 164ms/step\n",
      "100/79 [=====================================] - 16s 159ms/step\n",
      "Epoch 34/70\n",
      "82/79 [===============================] - 14s 173ms/step\n",
      "88/79 [=================================] - 15s 165ms/step\n",
      "92/79 [==================================] - 15s 162ms/step\n",
      "94/79 [===================================] - 15s 162ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 35/70\n",
      "82/79 [===============================] - 14s 172ms/step\n",
      "88/79 [=================================] - 14s 164ms/step\n",
      "92/79 [==================================] - 15s 161ms/step\n",
      "94/79 [===================================] - 15s 162ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 36/70\n",
      "82/79 [===============================] - 14s 171ms/step\n",
      "88/79 [=================================] - 15s 165ms/step\n",
      "92/79 [==================================] - 15s 162ms/step\n",
      "94/79 [===================================] - 15s 163ms/step\n",
      "100/79 [=====================================] - 16s 157ms/step\n",
      "Epoch 37/70\n",
      "82/79 [===============================] - 15s 181ms/step\n",
      "88/79 [=================================] - 15s 173ms/step\n",
      "92/79 [==================================] - 16s 169ms/step\n",
      "94/79 [===================================] - 16s 169ms/step\n",
      "100/79 [=====================================] - 16s 163ms/step\n",
      "Epoch 38/70\n",
      "82/79 [===============================] - 14s 170ms/step\n",
      "88/79 [=================================] - 14s 163ms/step\n",
      "92/79 [==================================] - 15s 160ms/step\n",
      "94/79 [===================================] - 15s 161ms/step\n",
      "100/79 [=====================================] - 16s 155ms/step\n",
      "Epoch 39/70\n",
      "82/79 [===============================] - 14s 170ms/step\n",
      "88/79 [=================================] - 14s 163ms/step\n",
      "92/79 [==================================] - 15s 161ms/step\n",
      "94/79 [===================================] - 15s 162ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 40/70\n",
      "82/79 [===============================] - 14s 174ms/step\n",
      "88/79 [=================================] - 15s 167ms/step\n",
      "92/79 [==================================] - 15s 164ms/step\n",
      "94/79 [===================================] - 16s 165ms/step\n",
      "100/79 [=====================================] - 16s 160ms/step\n",
      "Epoch 41/70\n",
      "82/79 [===============================] - 14s 177ms/step\n",
      "88/79 [=================================] - 15s 169ms/step\n",
      "92/79 [==================================] - 15s 166ms/step\n",
      "94/79 [===================================] - 16s 166ms/step\n",
      "100/79 [=====================================] - 16s 160ms/step\n",
      "Epoch 42/70\n",
      "82/79 [===============================] - 14s 173ms/step\n",
      "88/79 [=================================] - 15s 166ms/step\n",
      "92/79 [==================================] - 15s 162ms/step\n",
      "94/79 [===================================] - 15s 163ms/step\n",
      "100/79 [=====================================] - 16s 158ms/step\n",
      "Epoch 43/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 163ms/step\n",
      "92/79 [==================================] - 15s 160ms/step\n",
      "94/79 [===================================] - 15s 161ms/step\n",
      "100/79 [=====================================] - 15s 155ms/step\n",
      "Epoch 44/70\n",
      "82/79 [===============================] - 13s 164ms/step\n",
      "88/79 [=================================] - 14s 157ms/step\n",
      "92/79 [==================================] - 14s 154ms/step\n",
      "94/79 [===================================] - 15s 155ms/step\n",
      "100/79 [=====================================] - 15s 150ms/step\n",
      "Epoch 45/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 160ms/step\n",
      "92/79 [==================================] - 14s 157ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 152ms/step\n",
      "Epoch 46/70\n",
      "82/79 [===============================] - 14s 172ms/step\n",
      "88/79 [=================================] - 14s 165ms/step\n",
      "92/79 [==================================] - 15s 161ms/step\n",
      "94/79 [===================================] - 15s 163ms/step\n",
      "100/79 [=====================================] - 16s 157ms/step\n",
      "Epoch 47/70\n",
      "82/79 [===============================] - 14s 166ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "Epoch 48/70\n",
      "82/79 [===============================] - 14s 170ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 160ms/step\n",
      "94/79 [===================================] - 15s 161ms/step\n",
      "100/79 [=====================================] - 16s 156ms/step\n",
      "Epoch 49/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 159ms/step\n",
      "94/79 [===================================] - 15s 160ms/step\n",
      "100/79 [=====================================] - 15s 154ms/step\n",
      "Epoch 50/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 159ms/step\n",
      "100/79 [=====================================] - 15s 154ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5656717372237253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jindal/miniconda3/envs/NER2/lib/python3.5/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 159ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5645129230304237\n",
      "Epoch 52/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 162ms/step\n",
      "92/79 [==================================] - 15s 159ms/step\n",
      "94/79 [===================================] - 15s 159ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5661200863482391\n",
      "Epoch 53/70\n",
      "82/79 [===============================] - 14s 169ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 159ms/step\n",
      "100/79 [=====================================] - 15s 153ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.567513773393331\n",
      "Epoch 54/70\n",
      "82/79 [===============================] - 14s 168ms/step\n",
      "88/79 [=================================] - 14s 161ms/step\n",
      "92/79 [==================================] - 15s 158ms/step\n",
      "94/79 [===================================] - 15s 158ms/step\n",
      "100/79 [=====================================] - 15s 152ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5723644129323413\n",
      "Epoch 55/70\n",
      "82/79 [===============================] - 13s 163ms/step\n",
      "88/79 [=================================] - 14s 156ms/step\n",
      "92/79 [==================================] - 14s 153ms/step\n",
      "94/79 [===================================] - 14s 154ms/step\n",
      "100/79 [=====================================] - 15s 148ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5620775007873011\n",
      "Epoch 56/70\n",
      "82/79 [===============================] - 14s 173ms/step\n",
      "88/79 [=================================] - 15s 166ms/step\n",
      "92/79 [==================================] - 15s 162ms/step\n",
      "94/79 [===================================] - 15s 163ms/step\n",
      "100/79 [=====================================] - 16s 158ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.564336325123685\n",
      "Epoch 57/70\n",
      "82/79 [===============================] - 14s 167ms/step\n",
      "88/79 [=================================] - 14s 159ms/step\n",
      "92/79 [==================================] - 14s 156ms/step\n",
      "94/79 [===================================] - 15s 157ms/step\n",
      "100/79 [=====================================] - 15s 151ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5700033878101335\n",
      "Epoch 58/70\n",
      "82/79 [===============================] - 13s 158ms/step\n",
      "88/79 [=================================] - 13s 151ms/step\n",
      "92/79 [==================================] - 14s 148ms/step\n",
      "94/79 [===================================] - 14s 149ms/step\n",
      "100/79 [=====================================] - 14s 144ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5725668232948908\n",
      "Epoch 59/70\n",
      "82/79 [===============================] - 13s 161ms/step\n",
      "88/79 [=================================] - 14s 154ms/step\n",
      "92/79 [==================================] - 14s 150ms/step\n",
      "94/79 [===================================] - 14s 151ms/step\n",
      "100/79 [=====================================] - 15s 146ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.571670569329849\n",
      "Epoch 60/70\n",
      "82/79 [===============================] - 14s 165ms/step\n",
      "88/79 [=================================] - 14s 158ms/step\n",
      "92/79 [==================================] - 14s 155ms/step\n",
      "94/79 [===================================] - 15s 155ms/step\n",
      "100/79 [=====================================] - 15s 150ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5739262727269984\n",
      "Epoch 61/70\n",
      "82/79 [===============================] - 13s 162ms/step\n",
      "88/79 [=================================] - 14s 155ms/step\n",
      "92/79 [==================================] - 14s 152ms/step\n",
      "94/79 [===================================] - 14s 152ms/step\n",
      "100/79 [=====================================] - 15s 147ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5719519954921873\n",
      "Epoch 62/70\n",
      "82/79 [===============================] - 13s 157ms/step\n",
      "88/79 [=================================] - 13s 151ms/step\n",
      "92/79 [==================================] - 14s 148ms/step\n",
      "94/79 [===================================] - 14s 149ms/step\n",
      "100/79 [=====================================] - 14s 144ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5731667011355671\n",
      "Epoch 63/70\n",
      "82/79 [===============================] - 13s 157ms/step\n",
      "88/79 [=================================] - 13s 150ms/step\n",
      "92/79 [==================================] - 14s 147ms/step\n",
      "94/79 [===================================] - 14s 148ms/step\n",
      "100/79 [=====================================] - 14s 142ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5706028022276624\n",
      "Epoch 64/70\n",
      "82/79 [===============================] - 13s 161ms/step\n",
      "88/79 [=================================] - 14s 155ms/step\n",
      "92/79 [==================================] - 14s 152ms/step\n",
      "94/79 [===================================] - 14s 153ms/step\n",
      "100/79 [=====================================] - 15s 147ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5866867123448631\n",
      "Epoch 65/70\n",
      "82/79 [===============================] - 13s 161ms/step\n",
      "88/79 [=================================] - 14s 155ms/step\n",
      "92/79 [==================================] - 14s 152ms/step\n",
      "94/79 [===================================] - 14s 153ms/step\n",
      "100/79 [=====================================] - 15s 148ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5717466659928715\n",
      "Epoch 66/70\n",
      "82/79 [===============================] - 13s 156ms/step\n",
      "88/79 [=================================] - 13s 150ms/step\n",
      "92/79 [==================================] - 14s 147ms/step\n",
      "94/79 [===================================] - 14s 148ms/step\n",
      "100/79 [=====================================] - 14s 143ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5677482298446005\n",
      "Epoch 67/70\n",
      "82/79 [===============================] - 13s 157ms/step\n",
      "88/79 [=================================] - 13s 150ms/step\n",
      "92/79 [==================================] - 14s 147ms/step\n",
      "94/79 [===================================] - 14s 147ms/step\n",
      "100/79 [=====================================] - 14s 143ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5703608952404592\n",
      "Epoch 68/70\n",
      "82/79 [===============================] - 13s 161ms/step\n",
      "88/79 [=================================] - 14s 154ms/step\n",
      "92/79 [==================================] - 14s 151ms/step\n",
      "94/79 [===================================] - 14s 151ms/step\n",
      "100/79 [=====================================] - 15s 147ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5748845795085088\n",
      "Epoch 69/70\n",
      "82/79 [===============================] - 13s 161ms/step\n",
      "88/79 [=================================] - 14s 153ms/step\n",
      "92/79 [==================================] - 14s 151ms/step\n",
      "94/79 [===================================] - 14s 152ms/step\n",
      "100/79 [=====================================] - 15s 146ms/step\n",
      "2866/2867 [============================>.] - ETA: 0s0.5674632570574588\n",
      "51444\n"
     ]
    }
   ],
   "source": [
    "# for x in range(10):\n",
    "#     print(i)\n",
    "maxf1 = 0\n",
    "for epoch in range(epochs):    \n",
    "    print(\"Epoch %d/%d\"%(epoch, epochs))\n",
    "    a = Progbar(len(train_batch_len))\n",
    "    for i, batch in enumerate(iterate_minibatches(train_batch, train_batch_len)):\n",
    "        labels, tokens, casing, char = batch\n",
    "        labels = labels.tolist()\n",
    "#         print(labels)\n",
    "        for sentence in labels:\n",
    "            for i,label in enumerate(sentence):\n",
    "                temp = [0]*len(label2Idx)\n",
    "                value = label[0]\n",
    "                temp[value]=1\n",
    "                sentence[i] = temp\n",
    "        labels = np.array(labels)\n",
    "#         print(labels)\n",
    "        model.train_on_batch([tokens, casing, char], labels)\n",
    "        a.update(i)\n",
    "    if epoch >= 50:\n",
    "        predLabels, correctLabels = tag_dataset(dev_batch)        \n",
    "#         pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "        predLabels = np.concatenate(predLabels).ravel()\n",
    "        correctLabels = np.concatenate(correctLabels).ravel()\n",
    "        f1_dev = sklearn.metrics.f1_score(correctLabels,predLabels,average='macro' )\n",
    "        print(f1_dev)\n",
    "#         print(\"Dev-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_dev, rec_dev, f1_dev))\n",
    "\n",
    "        if f1_dev > maxf1:\n",
    "            model.save('german-CNN-BiLSTM-CRF.h5')\n",
    "            maxf1 = f1_dev\n",
    "#         predLabels, correctLabels = tag_dataset(dev_batch)        \n",
    "    #     with open(\"dropout=0.75.txt\",'w') as f:\n",
    "#         pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "    #     with open('dropout=0.75.txt') as f:\n",
    "    #         x = str(epoch)+ \" \"+f1_dev\n",
    "    #         f.write(x)\n",
    "    #         f.write('\\n')\n",
    "#         print(\"Dev-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_dev, rec_dev, f1_dev))\n",
    "\n",
    "\n",
    "id2word = {v: k for k, v in word2Idx.items()}\n",
    "print(len(correctLabels))        \n",
    "\n",
    "\n",
    "\n",
    "# command = \"perl nereval.perl\"\n",
    "# input_file= open(input_file_name)\n",
    "# output_file_name = '/home/jindal/notebooks/jindal/NER/1cnntest_result.txt'\n",
    "# output_file=open(output_file_name,'w')\n",
    "# import subprocess\n",
    "# process = subprocess.Popen(command.split(), stdin=input_file, stdout=output_file, cwd=r'/home/jindal/notebooks/Resources/GermEVAL')\n",
    "# out, err = process.communicate()\n",
    "# #     print(out)\n",
    "# print('******************************************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3004/3005 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model.load_weights('german-CNN-BiLSTM-CRF.h5')\n",
    "predLabels, correctLabels = tag_dataset(test_batch)        \n",
    "# pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "# print(\"Dev-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_dev, rec_dev, f1_dev))\n",
    "\n",
    "id = 1\n",
    "file_name='1cnntest.txt'\n",
    "input_file_name = '/home/jindal/notebooks/jindal/NER/'+file_name\n",
    "f = open(input_file_name,'wb')\n",
    "for sentence_number, batch in enumerate(test_batch):\n",
    "    for word_number, wordid in enumerate(batch[0]):\n",
    "        word = id2word[wordid]\n",
    "        true_label = correctLabels[sentence_number][word_number]\n",
    "        true_label = idx2Label[true_label]\n",
    "        pred_label = predLabels[sentence_number][word_number]\n",
    "        pred_label = idx2Label[pred_label]\n",
    "\n",
    "        string = str(id) + '\\t' + word + '\\t' + true_label +'\\t' + true_label+'\\t'+pred_label+'\\t'+pred_label+'\\t\\n'\n",
    "        string = string.encode()\n",
    "        f.write(string)\n",
    "        id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2866/2867 [============================>.] - ETA: 0sDev-Data: Prec: 0.000, Rec: 0.000, F1: 0.000\n"
     ]
    }
   ],
   "source": [
    "predLabels, correctLabels = tag_dataset(dev_batch)        \n",
    "pre_dev, rec_dev, f1_dev = compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Dev-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_dev, rec_dev, f1_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3004/3005 [============================>.] - ETA: 0sTest-Data: Prec: 0.000, Rec: 0.000, F1: 0.000\n"
     ]
    }
   ],
   "source": [
    "#   Performance on test dataset       \n",
    "predLabels, correctLabels = tag_dataset(test_batch)        \n",
    "pre_test, rec_test, f1_test= compute_f1(predLabels, correctLabels, idx2Label)\n",
    "print(\"Test-Data: Prec: %.3f, Rec: %.3f, F1: %.3f\" % (pre_test, rec_test, f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5099\n"
     ]
    }
   ],
   "source": [
    "id2word = {v: k for k, v in word2Idx.items()}\n",
    "print(len(correctLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'I-PERderiv', 1: 'I-LOCpart', 2: 'I-OTHderiv', 3: 'B-LOCderiv', 4: 'I-ORG', 5: 'I-ORGpart', 6: 'B-OTH', 7: 'B-PER', 8: 'B-LOCpart', 9: 'I-LOC', 10: 'I-ORGderiv', 11: 'B-OTHderiv', 12: 'I-PER', 13: 'B-ORGpart', 14: 'B-ORG', 15: 'I-OTH', 16: 'I-OTHpart', 17: 'B-PERpart', 18: 'O', 19: 'B-PERderiv', 20: 'B-OTHpart', 21: 'B-LOC', 22: 'I-LOCderiv', 23: 'I-PERpart', 24: 'B-ORGderiv'}\n"
     ]
    }
   ],
   "source": [
    "print(idx2Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "id = 1\n",
    "f = open('1cnntest.txt','wb')\n",
    "for sentence_number, batch in enumerate(test_batch):\n",
    "    for word_number, wordid in enumerate(batch[0]):\n",
    "        word = id2word[wordid]\n",
    "        true_label = correctLabels[sentence_number][word_number]\n",
    "        true_label = idx2Label[true_label]\n",
    "        pred_label = predLabels[sentence_number][word_number]\n",
    "        pred_label = idx2Label[pred_label]\n",
    "\n",
    "        if word.isalpha():\n",
    "            #string = str(id) + '\\t' + word + '\\t' + true_label +'\\t' + true_label+'\\t'+pred_label+'\\t'+pred_label+'\\t\\n'\n",
    "        \n",
    "            string = word + ' ' + pred_label+' '+pred_label+' '+true_label+'\\n'\n",
    "            string = string.encode()\n",
    "            f.write(string)\n",
    "            id+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.save('german-CNN-BiLSTM-CRF.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
